{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from trainer import MyTrainer\n",
    "from models import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checks for CUDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda enabled: True\n",
      "Compute device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \" + str(torch.cuda.is_available()))\n",
    "print(\"Cuda enabled: \" + str(torch.backends.cudnn.enabled))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"Compute device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Path management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base: str\n",
    "if os.getcwd() == \"/kaggle/working\":\n",
    "    base = \"/kaggle\"\n",
    "else:\n",
    "    base = os.getcwd()\n",
    "\n",
    "def get_full_dir(sub_dir: str) -> str:\n",
    "    return os.path.join(base, sub_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loads the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_path = get_full_dir(\"input/digit-recognizer/train.csv\")\n",
    "test_path = get_full_dir(\"input/digit-recognizer/test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Formats data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Separates labels\n",
    "x = df_train.drop(labels=\"label\", axis=1)\n",
    "y = df_train[\"label\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \nmean       0.0      0.0      0.0  ...      0.219286      0.117095   \nstd        0.0      0.0      0.0  ...      6.312890      4.633819   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reshapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "test_npa = df_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Updates shape to match image size 28x28x1 (only one channel per image)\n",
    "x = x.reshape(-1, 1, 28, 28)\n",
    "test_npa = test_npa.reshape(-1, 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Divides the train set to train and validation\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(x, y, test_size=0.2, random_state=8888)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Defines augmentation transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performs data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Performs data augmentation\n",
    "augmented_x_train = []\n",
    "augmented_y_train = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_train), y_train):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_train.append(transform(x_a))\n",
    "        augmented_y_train.append(y_a)\n",
    "    augmented_x_train.append(x_a)\n",
    "    augmented_y_train.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_train]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_train = np.concatenate(augmented_data_np, axis=0)\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_train = np.array(augmented_y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "augmented_x_dev = []\n",
    "augmented_y_dev = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_dev), y_dev):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_dev.append(transform(x_a))\n",
    "        augmented_y_dev.append(y_a)\n",
    "    augmented_x_dev.append(x_a)\n",
    "    augmented_y_dev.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_dev]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_dev = np.concatenate(augmented_data_np, axis=0)\n",
    "X_dev = X_dev.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_dev = np.array(augmented_y_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 201600 Dev size: 50400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \" + str(len(X_train)) + \" Dev size: \" + str(len(X_dev)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 9 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAGbCAYAAABqC/EcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiyUlEQVR4nO3de4xU9fnH8WfXDbgLgriE6zYu0YByMyigBVYIBdTSLlXDpdUKwhYREWrDVfwDubWpAZpoACVciiKipcodQkHkEraAQJGSFqKVYiXcEWSR2+7vj8lvmOcLOxdm5jnn7LxfSZP57OwOX8qz83jmOd9zsioqKioEAACYyPZ6AQAAZBIaLwAAhmi8AAAYovECAGCIxgsAgCEaLwAAhmi8AAAYovECAGCIxgsAgCEaLwAAhjKy8R46dEj69esnBQUFkpeXJ/fdd59MnDhRysrKvF4aEBW1i6Cidq/LyrRrNR85ckRat24ttWvXliFDhshdd90l27dvlwULFkhxcbEsW7bM6yUCN0XtIqioXS3H6wVYe/fdd+Xs2bOydetWadGihYiIDB48WMrLy2XhwoVy5swZqVOnjserBG5E7SKoqF0t4z5qPnfunIiI1K9fX329YcOGkp2dLdWqVfNiWUBM1C6CitrVMq7xdunSRUREBg0aJHv37pUjR47IkiVLZNasWTJ8+HCpUaOGtwsEKkHtIqioXUdFBpo0aVJFbm5uhYiE/zd+/HivlwXERO0iqKjd6zJuxisiUlhYKI8++qg8/fTTkp+fL6tWrZKpU6dKgwYNZNiwYV4vD6gUtYugonYjeN35rS1evLgiNze34siRI+rrAwYMqMjLy6s4efKkRysDoqN2EVTUrpZxM96ZM2dKmzZtpKCgQH29uLhYysrKZM+ePR6tDIiO2kVQUbtaxjXeY8eOybVr1274+pUrV0RE5OrVq9ZLAuJC7SKoqF0t4xpv06ZNZc+ePXLw4EH19cWLF0t2dra0bt3ao5UB0VG7CCpqV8u4K1dt3rxZunbtKvn5+TJs2DDJz8+XlStXypo1a6SkpETmzJnj9RKBm6J2EVTUrpZxjVdEZMeOHTJhwgTZs2ePnDp1Spo0aSL9+/eX0aNHS05ORp7ojYCgdhFU1O51Gdl4AQDwSsbNeAEA8BKNFwAAQzReAAAM0XgBADBE4wUAwBCNFwAAQ3FvnsrKykrnOpAG7BQLoXaDh9oNoXaDJ57a5YgXAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzleL0AAEDVt2PHjvDjtm3bRv3eLVu2qPzJJ5+ovGjRIpWPHz+e3OKMccQLAIAhGi8AAIZovAAAGGLGCwBIWMOGDVUeOHDgLb/W7t27VS4qKlK5U6dOKpeUlKj80ksvqbxp06ZbXosFjngBADBE4wUAwBCNFwAAQ1kVFRUVcX1jVla61xK3WLOFXr16qezuGYvcI+buDwv67CBSnP+0VZ6fajeVkv09cPlp7yS1G+Jl7T7yyCMqjxo1SuX27dtH/flGjRpV+lxpaanK1atXV/mJJ55QuXnz5iqvXr1a5WPHjqn88MMPq3zixImoa02leGqXI14AAAzReAEAMETjBQDAkC/38SY6W4g2SxAR2b59u8qPP/54pa9VWFio8rx581T2cnaAquf2229XeezYsSqvXbtW5cjfhWR/D9y5Wqy9k+6MF8EWq/bGjBmjcrVq1aK+3smTJ1WeM2eOysuWLQs/3rhxo3ouO1sfA9asWVPlevXqqeyu/eDBgypfunQp6lq9xhEvAACGaLwAABii8QIAYMiTGW+ys4VEZgkiImvWrKl0LVVtdgB/q1GjhsoLFixQ+amnnlI52u9Cor8Hic7V3L2Tn376qcpB3uOeiRKtvbNnz6pcVlam8rhx41R+5513kltghIsXL0Z9vlWrVip/8803Kp87dy6hPy9yD3vkfYNFRKZMmaLy6dOnE3rtm+GIFwAAQzReAAAM0XgBADBkdq3myPlCorOFdM4SXO5cK5WzAxGb+cH/43q3IX66VnOLFi1U3rdvn8o//PBD1Bz5u5DO3wMRkd69e6vs/t5Guz5usvvbqd2QVNZuorVXXFwc9fU2bNiQmoXFoVatWioXFBSonOj7dLdu3VRevnx5+LF7nk/Lli1VPnDgQNTX5lrNAAD4DI0XAABDNF4AAAyZzXgj5wuJzhYsZwnJijY7EEl+fpAI5mQhXs543bnaF198ofLSpUtVdueqXnLnamfOnFF5/fr1Kvfp0yf8ONFzIVzUbkg6Z7yxatHlp9pM1JtvvqnyM888o3Lt2rUr/Vl3z7DLfc9mxgsAgM/QeAEAMETjBQDAkNm1mv/5z3+GH7tzi9WrV6vs55nuvffeq/KIESNUdmcH7j1PmV1lNvff/5577vFoJbG5c9o6depEfT6aRPezI/3cWnSvp/CPf/zDcjkp5b5Pu9yZbuQ+4EmTJqnnOnTooLK7n/1WcMQLAIAhGi8AAIZovAAAGDLbxxvJ3f/3wAMPqNy0aVOV3Ws3p5M7x3I/31+8eLHK7j1M3f873WuIuvMDd15w9erVuNcaC/PkEC/38ebk6NMo3HtDu7Xv3h86qJLdzx55TkgmS2XturXoilWbfn5f7tWrl8r9+vVTOZH3affvmeg92NnHCwCAz9B4AQAw5MlHzS73kpHuJbiKiopUvnDhQlJ/XuPGjcOPS0pK1HNDhw5VuW7dulFf67PPPlN52bJlKs+ePVvlRD+2SAYfNYf46baAXbp0UXnt2rUqN2jQQGU/fZy3atUqlaNtrUvkknwiN16Wj4+aQyxrN1ZtpvN9OfI9WST592VXrPfpSMm+Z/NRMwAAPkPjBQDAEI0XAABDvpjxuq5du6byL3/5S5U//PDDqD+fm5ur8sCBA1UeMmRI+LF7qyz3/w53/jx58mSVf//730ddi5eY8Yb4acbr+s1vfqPyiy++qLKf5mhz585VOdqWjWS31V25ckXgbe26tenOPpN5X472niyS/PuyO8NN5e1WY2HGCwCAz9B4AQAwROMFAMCQL2e8M2bMUNm99d6vfvUrlS9evKjy+PHjVW7btm2lf9a2bdtUdmcF69ati75YH2PGG+LnGa97PsL333+vciJztETObRBJfI7mXubRFblXMtn97NRuiJe169bT1KlTVU7mfTnae7JIsN+XmfECAOAzNF4AAAzReAEAMOTLGa/rq6++UrmwsFDlROdBzz//fPjxwoULb3ldfsecLMTPM15XIuc3JHNug0jic7Rx48apnM69ktRuiJ9q984771R59+7dKifzvhz5niwS7PdlZrwAAPgMjRcAAEM0XgAADAVixvvBBx+o3LdvX5XLy8tVLisrU7l79+4q79q1K/z46tWrqViiLzEnC/HTnCyWROZoyZzbIOLvORq1G+Ln2k3mfTnae7JIsN+XmfECAOAzNF4AAAzReAEAMBSIGW+dOnVUPnXqlMruX+HEiRMqN2jQID0L8znmZCF+npPFEm2Olsy5DSL+nqNRuyF+ql33ffjzzz9XOdY+3sj35ar8nsyMFwAAn6HxAgBgiMYLAIChHK8XEI9nn31WZfcz9P3796tcv359lefOnavy0KFDw49j3RcUSKeXX35Z5VdeeUXlRK5/e+HCBZVLS0uTWxwQxd133x31+Vjvy5mMI14AAAzReAEAMETjBQDAUCBmvEVFRSq7e9vGjBmj8pNPPqlySUmJytOmTQs/TuU9RIFEubUda272xRdfhB+7M7OqvDcS3nPPtXG9/fbbKrv3a16xYkX4cbTzbkSq/rk3HPECAGCIxgsAgCEaLwAAhnw543WvCdq5c2eV3b2MLVu2VHn69OkquzNewCuxats9fyHa3CxyZibC3AzpFetcG9fatWtVnjdvXvhxtPNuRKr+uTcc8QIAYIjGCwCAIRovAACGfDnjPXPmjMqtWrVS2d0f9tprr6ncrl27qK//2GOPhR9X9VkC/OW7775TeePGjSr36dNHZfd6t5Fzs8iZmQhzM6RWoufauLXqijz3JtZ5N82bN1e5qtUuR7wAABii8QIAYMiXHzW7jh8/rnLPnj1Vfuutt1Tu27evyt9++63K69atS+HqgPiVl5cn9P25ubmVPse2OaRTomORaLUaS+T472b4qBkAANwyGi8AAIZovAAAGMqqcM8Jr+wbY1weDP4T5z9tlefn2q1Xr57K7la5+++/X+XI8xPcLRduHjlypMozZsy45XVao3ZD/FS7ydSqiK5Pt1Zd7hbSIM1446ldjngBADBE4wUAwBCNFwAAQ4HYxwtUVcnuUY/EfnWkUypr1eXWblXHES8AAIZovAAAGKLxAgBgiH28VRh7IUOo3eChdkOo3eBhHy8AAD5D4wUAwBCNFwAAQ3HPeAEAQPIy8oj30KFD0q9fPykoKJC8vDy57777ZOLEiVJWVub10oCoqF0EFbV7XcYd8R45ckRat24ttWvXliFDhshdd90l27dvlwULFkhxcfENd9wA/ILaRVBRu1rGXTLy3XfflbNnz8rWrVulRYsWIiIyePBgKS8vl4ULF8qZM2ekTp06Hq8SuBG1i6CidrWM+6j53LlzIiJSv3599fWGDRtKdna2VKtWzYtlATFRuwgqalfLuMbbpUsXEREZNGiQ7N27V44cOSJLliyRWbNmyfDhw6VGjRreLhCoBLWLoKJ2HRUZaNKkSRW5ubkVIhL+3/jx471eFhATtYugonavy7gZr4hIYWGhPProo/L0009Lfn6+rFq1SqZOnSoNGjSQYcOGeb08oFLULoKK2o3gdee3tnjx4orc3NyKI0eOqK8PGDCgIi8vr+LkyZMerQyIjtpFUFG7WsbNeGfOnClt2rSRgoIC9fXi4mIpKyuTPXv2eLQyIDpqF0FF7WoZ13iPHTsm165du+HrV65cERGRq1evWi8JiAu1i6CidrWMa7xNmzaVPXv2yMGDB9XXFy9eLNnZ2dK6dWuPVgZER+0iqKhdLeOuXLV582bp2rWr5Ofny7BhwyQ/P19Wrlwpa9askZKSEpkzZ47XSwRuitpFUFG7WsY1XhGRHTt2yIQJE2TPnj1y6tQpadKkifTv319Gjx4tOTkZeaI3AoLaRVBRu9dlZOMFAMArGTfjBQDASzReAAAM0XgBADBE4wUAwBCNFwAAQzReAAAM0XgBADAU967lrKysdK4DacAW7RBqN3io3RBqN3jiqV2OeAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAEI0XAABDNF4AAAzReAEAMETjBQDAUI7XCwAABF/Dhg1VHjhwoMq9evUKP27btm3U19qyZYvKn3zyicqLFi1S+fjx4/Eu0xc44gUAwBCNFwAAQzReAAAMZVVUVFTE9Y1ZWeleS9q4s4ejR496tBJbcf7TVnlBrt1MRe2G+Kl2H3nkEZVHjRqlcvv27VVu1KhRpa9VWlqqcvXq1VV+8MEHVXbr4V//+pfKL730ksqbNm2q9M9Ot3hqlyNeAAAM0XgBADBE4wUAwFCVmPHGmj0MGzZM5cj9ZZF7y0Sq1v4y5mQhfq5d3By1G2JZu7fffrvKY8eOVXnMmDEqV6tWTeWTJ0+q/PHHH6u8bNmy8OONGzeq57Kz9TFgzZo1VW7evLnKq1evVvnYsWMqP/zwwyqfOHFCrDDjBQDAZ2i8AAAYovECAGAoENdqTnb2kMj+su3bt6vs7i8rKipSuVOnTiqXlJSo3KJFi0r/LCCdXnnlFZVnzJjh0UrgRzVq1FB5wYIFKj/11FMqnz17VuURI0ao/M4776RsbRcvXlS5Xr16Krs94eDBgypfunQpZWtJB454AQAwROMFAMAQjRcAAEO+3Meb7Oxh3LhxKk+aNEnlyP1lkXvLRFK/v6xnz54qW15DlL2QIX7ex5vIPUxFYu8zjxSk69u6qN2QdNaue/7Jvn37VP7hhx9ULi4uVnnDhg3pWdhN1KpVS+WCggKVv/nmG5XPnTuX0OtHXp9hx44d6rkpU6aofPr06aivxT5eAAB8hsYLAIAhGi8AAIZ8sY830VmDm/v06aPyPffco3L9+vWTXWJYovvL5s2bp7KX1xCF95YuXapyInvMRfQ+827duqnnEj3/gNpEJHee7NaL5UzX5c5sDxw4kNTrub87Dz30UPhxx44d1XNz585VOdaMNx4c8QIAYIjGCwCAIRovAACGfDHjdcWaNfTu3Tvqz1vOItatWxf1+aBdQxTJiXVd8Z/+9Kcqu9cVnzNnjsrR9pm7tWR9fdtp06apHLnfMRVzMNhy95+658oEyb333quye13pZ555RuXIa/Jb7CHniBcAAEM0XgAADNF4AQAw5MsZb5BmDe7+slatWqmczDVEI68fKpL8NUSRen6+p6l7/kGytenufXzxxRdVjrz/r3uNc/jPv//9b5Xd69Q/8MADKt95550qu7WcTnXq1FG5Q4cOKrvXNO/Xr5/K7h53t8dE/i641/Z3z4VIBX47AAAwROMFAMAQjRcAAEO+uB9vTo4eNa9Zs0Zld9bQtGlTlS1nDekWOUdbvny5es7dh9myZUuV3euXck/TEO5pemvefPNNld29j7Vr1670Z915cqLX1qV2QyzvJd2lSxeV165dq7L7b1hUVKTyhQsXbvnPbty4scolJSUqDx06VOW6desm9PqfffaZyu7++NmzZ4cfJ3utBe7HCwCAz9B4AQAw5IvtRFevXlXZ3SbjfuThnvb+4IMPpmdhN+Ge1n7mzJmo35/opcsiRV7GTISP34LAz7dWi8XdTpTIFgwRvQ0jHVswkF6bNm1S+eWXX1Y58uNYEZGePXuq/OGHH0Z9/dzc3PDjgQMHqueGDBmisjvCcWvPHeFMnjxZZfej5GRvI5hqHPECAGCIxgsAgCEaLwAAhnwx43UlOmtwL9tneVq7O6tI5aXLRo8erZ5zL0fozsbhPT9f7tSdybnb1Vzu72G0LRgi3PKyqnnvvfdUbt68ucoffPCByu5lQt3bVI4fPz78uG3btlH/7G3btqnsznBj3Y7V7zjiBQDAEI0XAABDNF4AAAz54pKRsUTu/xIRmTp1qsrbt29X2XI/WaL8dumyTGBZu+vXr1fZ8nKniZ6f4J5v0K5dO5W93PtI7YZ4+b7rcm8LuHv3bpULCwtVTuTf8Pnnn1d54cKFCa3NT7hkJAAAPkPjBQDAEI0XAABDvtzH63L3g73++usqnz59WmXL/WR//etfoz7v92uGIrW6d++usnurNfc643/4wx9UTuf5CU888YTKQd8LCVvu+Qg7duxQuUmTJiq7s86ysrLwY/f3ZNeuXSlYYXBwxAsAgCEaLwAAhmi8AAAYCsSMN5avv/5a5ffff1/laPuq3Odi7Sd77LHHVHavEw1Ecq93PGvWLJV//OMfq5zO8xOY6SIZ7r3I27dvr3Ks/auR19AvLS1N3cICiCNeAAAM0XgBADBE4wUAwFAgZrzubMGdk7n7x8rLy6O+XjL7yZiTIRlz5sxROdb1b+++++5KXyvR8xOAZDz77LMqR6tNEZH9+/erXL9+/ZSvKag44gUAwBCNFwAAQzReAAAMBWLG684WEt0/duLECZUbNGiQmoUBSUr0+reR5y907NhRPZfpeyORXkVFRSq79wp+++23VXavU79ixYrw47lz56rn3HtFJ3svcr/jiBcAAEM0XgAADNF4AQAwFIgZr4v9Y6gqkrn+7SeffKIy5y4gldza7Ny5s8pubbrvu2vXrlV53rx54cclJSXquWnTpqlc1e9bzhEvAACGaLwAABii8QIAYMiXM153tpDK/WMieg9Zpu0fg78kc/3b5s2bq+cyfW8kUuu7775TeePGjSr36dNH5dzc3KivN3369PBjd8abaTjiBQDAEI0XAABDNF4AAAz5csbrzhZSuX9MRM8XMm3/GPwlmfMXnnzySfVcpu+NRGq59zUfMWKEyoWFhSq/9tprKrdr105l95yESI899pjKVb1WOeIFAMAQjRcAAEO+/KjZ/Ygjlaexi3AqO7yTysvw/ec//1HPUddIp+PHj6vcs2dPld966y2V+/btW+lrffvttyqvW7cuydUFC0e8AAAYovECAGCIxgsAgKGsimj3HYv8Rmebg6V69eqp7F4S8v7771fZnRe4p7FH5pEjR6rnZsyYccvr9Js4/2mrPC9rN5bsbP3fvleuXFH5/PnzKkfWdrS6Fgl2bVO7IX6uXdxcPLXLES8AAIZovAAAGKLxAgBgyJf7eF2p3D8moveQZdr+MfiLu2e9YcOGKv/pT39Smb2RQPBxxAsAgCEaLwAAhmi8AAAYCsQ+Xtwa9kKGULvBQ+2GULvBwz5eAAB8hsYLAIAhGi8AAIbinvECAIDkZeQR7+effy6PP/641KpVS+644w7p0aOH7N271+tlATFRuwgqave6jDvi3b17t3Ts2FF+9KMfyQsvvCDl5eUyc+ZMOX36tOzYsUOaNWvm9RKBm6J2EVTUrpZxjbdnz56yfft2OXTokOTn54uIyNGjR6Vp06bSo0cPWbp0qccrBG6O2kVQUbtaxn3UvGXLFunWrVv4H18kdH3czp07y8qVK+X777/3cHVA5ahdBBW1q2Vc47106ZLk5ube8PW8vDy5fPmy7N+/34NVAbFRuwgqalfLuMbbrFkzKS0tlWvXroW/dvnyZfn73/8uIiL/+9//vFoaEBW1i6CidrWMa7xDhw6VgwcPyqBBg+TAgQOyf/9+ee655+To0aMiInLx4kWPVwjcHLWLoKJ2tYxrvEOGDJFXX31V3n//fWnRooW0atVKvvzySxk9erSIiNSsWdPjFQI3R+0iqKhdLeMar4jIlClT5NixY7JlyxbZt2+f7Ny5M3xD8qZNm3q8OqBy1C6Citq9LuO2E1Wmffv2cvToUTl8+LBkZ2fkf48goKhdBFWm1m7m/E2jWLJkiezcuVN++9vfZtQ/PoKP2kVQZXLtZtwR7+bNm2XixInSo0cPyc/Pl9LSUpk/f750795dVqxYITk5OV4vEbgpahdBRe1qmfW3FZHGjRvLbbfdJm+88YacP39emjRpIpMnT5bf/e53GfePj2ChdhFU1K6WcUe8AAB4KbM+WAcAwGM0XgAADNF4AQAwROMFAMAQjRcAAEM0XgAADMW9gSorKyud60AasFMshNoNHmo3hNoNnnhqlyNeAAAM0XgBADBE4wUAwBCNFwAAQzReAAAM0XgBADBE4wUAwBCNFwAAQzReAAAM0XgBADBE4wUAwBCNFwAAQzReAAAM0XgBADBE4wUAwBCNFwAAQzReAAAM0XgBADCU4/UC0uGNN95Q+fHHH1e5efPmlf7srl27VJ4wYYLKa9asSW5xQIrUq1dP5VGjRqmcSN2LUPuAFY54AQAwROMFAMAQjRcAAENZFRUVFXF9Y1ZWutdSqTvuuCPq899++63KeXl5Ksf5V7yp48ePq9yoUaNbfi1ryfy9qxIvazdZbu3/7Gc/Cz9+55131HOprHsRb2uf2g0Jcu1mqnhqlyNeAAAM0XgBADBE4wUAwJAvZ7y5ubkqL1q0SOXi4mKV//KXv6jcu3dvld2/4u7du8OPT506pZ7r3Lmzyu7fO3LGJiKyYcMG8SvmZCFBmpO5M9358+er/Itf/KLSn3X/ntHqXsTftU/thgSpdhNRlfegM+MFAMBnaLwAABii8QIAYMiXM95jx46pnJ+fr/LYsWNVnj59usrl5eUqt2zZUuXDhw+HH58/f14997e//U3l1q1bq9ysWTOVz5w5I37FnCzEz3OyRM9niOSe27Bu3TqVd+7cqXJk3Yv4u/ap3RA/124s7EGvHEe8AAAYovECAGCIxgsAgCFf3I+3S5cuKrt7vEaOHKnytGnTEnr9/fv3x/29a9euVdndP+bnmS6C5+uvv1bZPZ/BFXl+Q6xzGxJF7SMZyexBjyXRPeh16tRR+Sc/+YnKXl9/gSNeAAAM0XgBADBE4wUAwJAnM1738/fXX39d5cmTJ6uc6Ew3mbW4brvtNpXdfZcXL15M+ZpQdcU6n+Hy5csqv/rqqyqn83fBRe0jGrce/vznP6vspz3o7ozYaxzxAgBgiMYLAIAhGi8AAIY8mfG69/Xs2LGjyhMnTkzrnx+5V3LJkiXqOXcG514rNSfHF1ufERCxzmdw997+8Y9/VNny/Iaf//znKtetW1fl9957T+UBAwao7M7dULWxB/3WccQLAIAhGi8AAIZovAAAGDIbWEbeD3H48OHquU2bNqmc7uto/vrXvw4/dme6QCrFOp/B3bfr/i6kkjuDc89vcNfm6tWrl8qPPPKIyuvXr09idfA79qCnDke8AAAYovECAGCIxgsAgCGzGW///v3Dj9u0aaOeq127ttmfLSIyderUuH/Wvc8jexURTeS5DCI3ns/g2rZtm8rpPL8h8twGkcTPbzh48KDKpaWlyS4JPsYe9PThiBcAAEM0XgAADJl91Bz5ka17GcYLFy5E/dnq1aurHOtWfsuXL1f5oYceimeJInLjra22bt0a988C7ljDHau43C066VxLIiMWEZGysjKVBw8erDJjl6qNrXDpwxEvAACGaLwAABii8QIAYMhsxhv5mXpFRYV67tq1ayqPHz9e5a5du0bNLneG7P550QwcODDu7wVcsW4r6Url+Q3JnNtwMx999JHKnO9QtbEVzg5HvAAAGKLxAgBgiMYLAIAhsxlv5OXG3njjjajfO3ny5HQvJ+zll182+7NQ9bnnE8Q6v2DWrFkqHz58WOVEzm9I5twGEZHVq1erzPkOmYU96HY44gUAwBCNFwAAQzReAAAMZVXEOQiKtR8xltzc3PDjO+64I+pru0tyrwl69uxZld3rbr7wwgsqu3vAvvrqq/Djtm3bqufOnTvnLj2wEp3xVVXJ1m4innzySZXnz5+vcs2aNVVOdi6bytdyz3dw58+WqN0Qy9pdt26dyt26dYv6/bfddlvU573cg+5ec9/yfIV4apcjXgAADNF4AQAwROMFAMCQ2T7eixcv3vRxKrjXdnbnaK7nnnsu/LgqzXThvY8//ljlwsJClWPtYXcdPXpU5cjr4c6ePVs9F+vcBlfkuQ4iIosWLUpobaha2INuhyNeAAAM0XgBADBE4wUAwJDZPt5UcvdKLly4UOW8vDyVCwoKVL569Wr48YkTJ1K8Ov9gL2SIl7UbuX9dJPV72CN9+umnKhcVFUVdW6dOnVT2+h6lkajdEPagxydoe9A54gUAwBCNFwAAQzReAAAMme3jTYZ73U539uDO0UpKSlR290ICVtw966ncw75ixQqVu3TponJ5ebnKe/fuVfnLL79M2VoQfOxBt8MRLwAAhmi8AAAYovECAGDIl/t43fs2fvTRRyq7syxXTk4gRtdpx17IED/tQU9W5F7LWPvX//vf/6rcoUMHlf187gO1G8Ie9JsL+h50jngBADBE4wUAwBCNFwAAQ74chj711FMqx5rp1q5dO42rAbwTbQ+7O4NzZ2oTJ05U2c8zXfgPe9DThyNeAAAM0XgBADBE4wUAwJAv9/EiNdgLGRKk2k1mD7t7Ld1x48albF3WqN2QINVuLOxBv44jXgAADNF4AQAwxEfNVRgf14UEqXYHDRqk8ttvvx33z7rb6i5cuJCSNXmB2g0JUu263K1wkbcFrFmzpnruypUrKg8dOlRl91awfsZHzQAA+AyNFwAAQzReAAAMMeOtwpiThVC7wUPthgSpdtkKF8KMFwAAn6HxAgBgiMYLAIAhZrxVGHOyEGo3eKjdkCDVLnvQQ5jxAgDgMzReAAAM0XgBADDEjLcKY04WQu0GD7UbQu0GDzNeAAB8hsYLAIAhGi8AAIbinvECAIDkccQLAIAhGi8AAIZovAAAGKLxAgBgiMYLAIAhGi8AAIZovAAAGKLxAgBgiMYLAICh/wN375US462pIwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Converts data to tensors and normalize them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#train\n",
    "X_train_tensor = torch.tensor(X_train)/255.0\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "train_tensor = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "#val\n",
    "X_dev_tensor = torch.tensor(X_dev)/255.0\n",
    "y_dev_tensor = torch.tensor(y_dev)\n",
    "dev_tensor = TensorDataset(X_dev_tensor, y_dev_tensor)\n",
    "\n",
    "#test\n",
    "test_image_tensor = torch.tensor(test_npa)/255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defines data loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "dev_loader = DataLoader(dev_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_image_tensor, batch_size=16, num_workers=2, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creates mode, loss and optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model = MyConNet5()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.50)\n",
    "trainer = MyTrainer(model, optimizer, loss_function)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fits the model to data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [10080/201600 (5%)]\t\tLoss: 0.073219\n",
      "Train Epoch: 0 [20160/201600 (10%)]\t\tLoss: 0.070039\n",
      "Train Epoch: 0 [30240/201600 (15%)]\t\tLoss: 0.057977\n",
      "Train Epoch: 0 [40320/201600 (20%)]\t\tLoss: 0.056708\n",
      "Train Epoch: 0 [50400/201600 (25%)]\t\tLoss: 0.060147\n",
      "Train Epoch: 0 [60480/201600 (30%)]\t\tLoss: 0.062071\n",
      "Train Epoch: 0 [70560/201600 (35%)]\t\tLoss: 0.066862\n",
      "Train Epoch: 0 [80640/201600 (40%)]\t\tLoss: 0.061695\n",
      "Train Epoch: 0 [90720/201600 (45%)]\t\tLoss: 0.056511\n",
      "Train Epoch: 0 [100800/201600 (50%)]\t\tLoss: 0.062538\n",
      "Train Epoch: 0 [110880/201600 (55%)]\t\tLoss: 0.059319\n",
      "Train Epoch: 0 [120960/201600 (60%)]\t\tLoss: 0.062732\n",
      "Train Epoch: 0 [131040/201600 (65%)]\t\tLoss: 0.050675\n",
      "Train Epoch: 0 [141120/201600 (70%)]\t\tLoss: 0.058784\n",
      "Train Epoch: 0 [151200/201600 (75%)]\t\tLoss: 0.052721\n",
      "Train Epoch: 0 [161280/201600 (80%)]\t\tLoss: 0.057396\n",
      "Train Epoch: 0 [171360/201600 (85%)]\t\tLoss: 0.062646\n",
      "Train Epoch: 0 [181440/201600 (90%)]\t\tLoss: 0.061682\n",
      "Train Epoch: 0 [191520/201600 (95%)]\t\tLoss: 0.058757\n",
      "Train Epoch: 0 [201600/201600 (100%)]\t\tLoss: 0.056963\n",
      "Train Epoch: 0 Average Loss: 0.060472\n",
      "\n",
      "The loss after 1 epochs was 0.0211 \n",
      "\n",
      "Train Epoch: 1 [10080/201600 (5%)]\t\tLoss: 0.054977\n",
      "Train Epoch: 1 [20160/201600 (10%)]\t\tLoss: 0.052306\n",
      "Train Epoch: 1 [30240/201600 (15%)]\t\tLoss: 0.049836\n",
      "Train Epoch: 1 [40320/201600 (20%)]\t\tLoss: 0.064295\n",
      "Train Epoch: 1 [50400/201600 (25%)]\t\tLoss: 0.054273\n",
      "Train Epoch: 1 [60480/201600 (30%)]\t\tLoss: 0.057324\n",
      "Train Epoch: 1 [70560/201600 (35%)]\t\tLoss: 0.056591\n",
      "Train Epoch: 1 [80640/201600 (40%)]\t\tLoss: 0.056809\n",
      "Train Epoch: 1 [90720/201600 (45%)]\t\tLoss: 0.054895\n",
      "Train Epoch: 1 [100800/201600 (50%)]\t\tLoss: 0.060061\n",
      "Train Epoch: 1 [110880/201600 (55%)]\t\tLoss: 0.052599\n",
      "Train Epoch: 1 [120960/201600 (60%)]\t\tLoss: 0.048198\n",
      "Train Epoch: 1 [131040/201600 (65%)]\t\tLoss: 0.058636\n",
      "Train Epoch: 1 [141120/201600 (70%)]\t\tLoss: 0.056045\n",
      "Train Epoch: 1 [151200/201600 (75%)]\t\tLoss: 0.057777\n",
      "Train Epoch: 1 [161280/201600 (80%)]\t\tLoss: 0.052282\n",
      "Train Epoch: 1 [171360/201600 (85%)]\t\tLoss: 0.057230\n",
      "Train Epoch: 1 [181440/201600 (90%)]\t\tLoss: 0.057195\n",
      "Train Epoch: 1 [191520/201600 (95%)]\t\tLoss: 0.051641\n",
      "Train Epoch: 1 [201600/201600 (100%)]\t\tLoss: 0.051168\n",
      "Train Epoch: 1 Average Loss: 0.055207\n",
      "\n",
      "The loss after 2 epochs was 0.0197 \n",
      "\n",
      "Train Epoch: 2 [10080/201600 (5%)]\t\tLoss: 0.048686\n",
      "Train Epoch: 2 [20160/201600 (10%)]\t\tLoss: 0.048417\n",
      "Train Epoch: 2 [30240/201600 (15%)]\t\tLoss: 0.056499\n",
      "Train Epoch: 2 [40320/201600 (20%)]\t\tLoss: 0.054172\n",
      "Train Epoch: 2 [50400/201600 (25%)]\t\tLoss: 0.050966\n",
      "Train Epoch: 2 [60480/201600 (30%)]\t\tLoss: 0.056930\n",
      "Train Epoch: 2 [70560/201600 (35%)]\t\tLoss: 0.054407\n",
      "Train Epoch: 2 [80640/201600 (40%)]\t\tLoss: 0.051503\n",
      "Train Epoch: 2 [90720/201600 (45%)]\t\tLoss: 0.051787\n",
      "Train Epoch: 2 [100800/201600 (50%)]\t\tLoss: 0.049970\n",
      "Train Epoch: 2 [110880/201600 (55%)]\t\tLoss: 0.053079\n",
      "Train Epoch: 2 [120960/201600 (60%)]\t\tLoss: 0.053908\n",
      "Train Epoch: 2 [131040/201600 (65%)]\t\tLoss: 0.049943\n",
      "Train Epoch: 2 [141120/201600 (70%)]\t\tLoss: 0.056156\n",
      "Train Epoch: 2 [151200/201600 (75%)]\t\tLoss: 0.056551\n",
      "Train Epoch: 2 [161280/201600 (80%)]\t\tLoss: 0.043256\n",
      "Train Epoch: 2 [171360/201600 (85%)]\t\tLoss: 0.050057\n",
      "Train Epoch: 2 [181440/201600 (90%)]\t\tLoss: 0.049031\n",
      "Train Epoch: 2 [191520/201600 (95%)]\t\tLoss: 0.057233\n",
      "Train Epoch: 2 [201600/201600 (100%)]\t\tLoss: 0.048987\n",
      "Train Epoch: 2 Average Loss: 0.052077\n",
      "\n",
      "The loss after 3 epochs was 0.02\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_loader, dev_loader, epochs=50, eval_every=1, sub_epoch_logs=True, sub_epoch_percentile=0.05)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def make_predictions(data_loader):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    test_predictions = torch.LongTensor()\n",
    "\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        output = model(data)\n",
    "\n",
    "        predictions = torch.max(output, dim=1)[1]\n",
    "        test_predictions = torch.cat((test_predictions, predictions), dim=0)\n",
    "\n",
    "    return test_predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "test_set_predictions = make_predictions(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "submission_df = get_full_dir(\"input/digit-recognizer/sample_submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      0\n4        5      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['Label'] = test_set_predictions.numpy().squeeze()\n",
    "submission_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/myNet5tmp.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
