{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from trainer import MyTrainer\n",
    "from models import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checks for CUDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda enabled: True\n",
      "Compute device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \" + str(torch.cuda.is_available()))\n",
    "print(\"Cuda enabled: \" + str(torch.backends.cudnn.enabled))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"Compute device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Path management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "base: str\n",
    "if os.getcwd() == \"/kaggle/working\":\n",
    "    base = \"/kaggle\"\n",
    "else:\n",
    "    base = os.getcwd()\n",
    "\n",
    "def get_full_dir(sub_dir: str) -> str:\n",
    "    return os.path.join(base, sub_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loads the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_path = get_full_dir(\"data/raw/train.csv\")\n",
    "test_path = get_full_dir(\"data/raw/test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Formats data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Separates labels\n",
    "x = df_train.drop(labels=\"label\", axis=1)\n",
    "y = df_train[\"label\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \nmean       0.0      0.0      0.0  ...      0.219286      0.117095   \nstd        0.0      0.0      0.0  ...      6.312890      4.633819   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reshapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "test_npa = df_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Updates shape to match image size 28x28x1 (only one channel per image)\n",
    "x = x.reshape(-1, 1, 28, 28)\n",
    "test_npa = test_npa.reshape(-1, 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Divides the train set to train and validation\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(x, y, test_size=0.2, random_state=8888)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Defines augmentation transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Performs data augmentation\n",
    "augmented_x_train = []\n",
    "augmented_y_train = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_train), y_train):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_train.append(transform(x_a))\n",
    "        augmented_y_train.append(y_a)\n",
    "    augmented_x_train.append(x_a)\n",
    "    augmented_y_train.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_train]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_train = np.concatenate(augmented_data_np, axis=0)\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_train = np.array(augmented_y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "augmented_x_dev = []\n",
    "augmented_y_dev = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_dev), y_dev):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_dev.append(transform(x_a))\n",
    "        augmented_y_dev.append(y_a)\n",
    "    augmented_x_dev.append(x_a)\n",
    "    augmented_y_dev.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_dev]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_dev = np.concatenate(augmented_data_np, axis=0)\n",
    "X_dev = X_dev.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_dev = np.array(augmented_y_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1041600 Dev size: 260400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \" + str(len(X_train)) + \" Dev size: \" + str(len(X_dev)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 9 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAGbCAYAAABqC/EcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmdUlEQVR4nO3df2xV9f3H8TeVgAVCLe2gYDeLGOaohQiIBkU6piMLS3H+APwVEao2yI/MTNFBjIqQ/TFwMQoIkzQoQ12cVMXSJXb4KyWNUCbKEBP3R42ugFAxFAjQfv+4+V7u+w09t4d77+ecc+/zkZicVy+9PZG3fXvu+3w+p1dXV1eXAAAAJ/KCPgEAAHIJjRcAAIdovAAAOETjBQDAIRovAAAO0XgBAHCIxgsAgEM0XgAAHKLxAgDgEI0XAACHcrLxfvXVVzJr1iwpLS2Vfv36yZVXXinPPPOMdHR0BH1qgCdqF1FF7Z7VK9f2am5tbZXRo0dLQUGB1NTUyKBBg6SpqUlqa2ulqqpK6urqgj5F4LyoXUQVtav1DvoEXHvllVekvb1dPv74YykvLxcRkQcffFA6Oztl48aNcuTIESksLAz4LIFzUbuIKmpXy7mPmo8ePSoiIkOGDFFfHzp0qOTl5UmfPn2COC0gKWoXUUXtajnXeCsrK0VEZO7cubJ7925pbW2V119/XdasWSMLFy6U/v37B3uCQDeoXUQVtWt05aBly5Z15efnd4lI/J8lS5YEfVpAUtQuooraPSvnZrwiImVlZXLjjTfKbbfdJkVFRbJ161ZZsWKFlJSUyPz584M+PaBb1C6iitpNEHTnd23z5s1d+fn5Xa2trerrs2fP7urXr1/XoUOHAjozwBu1i6iidrWcm/GuXr1arr76aiktLVVfr6qqko6ODmlpaQnozABv1C6iitrVcq7xtrW1yZkzZ875+qlTp0RE5PTp065PCegRahdRRe1qOdd4R44cKS0tLbJ//3719c2bN0teXp6MHj06oDMDvFG7iCpqV8u5nas+/PBDmTJlihQVFcn8+fOlqKhI3n33Xamvr5fq6mpZv3590KcInBe1i6iidrWca7wiIs3NzfLUU09JS0uLfP/99zJ8+HC577775LHHHpPevXPyRm9EBLWLqKJ2z8rJxgsAQFBybsYLAECQaLwAADhE4wUAwCEaLwAADtF4AQBwiMYLAIBDPV481atXr0yeBzKAlWIx1G70ULsx1G709KR2ueIFAMAhGi8AAA7ReAEAcIjGCwCAQzReAAAcovECAOAQjRcAAIdy6yGIAIDQ+f3vf6/ypk2bVD5w4IDL08k4rngBAHCIxgsAgEM0XgAAHOrV1cNNUdkzNHrY7zYmSrU7dOhQlefMmaPy8uXLXZ5OYKjdmDDVbrLanD59usrjx4/v9r0++ugjlW+44QaV9+3bp/LDDz+s8vbt2z3PNUjs1QwAQMjQeAEAcIjGCwCAQ8x4sxhzspgw1e51112n8qOPPqryhAkTVB42bJjKO3fujB97zdBEzp2jbdmyRWW7VtIKcu0ktRsTZO2++eabKierTWvHjh0q9+3bN348duxY9dovf/lLld977z2V29raVL722mtVPnjwoOe5uMSMFwCAkKHxAgDgEFtGAml08cUXq/z444+rvHjxYpX79Omj8qFDhzzff9y4cfHjpqYm9VriR3kiIpMmTVLZLtmorq5W2S7ZyLZt+uDNjkFuueUWlW1trl+/XuW6ujqVGxsbVc7LO3udN2DAAPVaZWWlyva/o/3796t88uRJScXKlStVTlymd/jw4ZTeuye44gUAwCEaLwAADtF4AQBwiOVEWYwlGTHprN3+/ft7vl5bW6vyrbfeqnJ7e7vKTzzxhMrr1q1Tee3atSonztG8Zmgi587RRo0apbJdsjFt2jSVg9yWj9qNSWftpnr/wUUXXZS2c7EGDhyocmlpqcrffPONykePHvX1/nZp3fXXX6/yVVdd1e337t2719fPYjkRAAAhQ+MFAMAhGi8AAA5l5TpeP4+vSve2e6x9zG5lZWUqf/bZZyqfOHFC5V//+tee7/f+++97vl5TU9PzkzOOHz+u8uDBg1W2M78NGzaoHOZt+dAzifck+L3/YNGiRZk6raT8zlWTefrpp1VuaGhQec+ePfHjioqKtP7s8+GKFwAAh2i8AAA4ROMFAMChSM54U320WqJM73cb5FpIZJ5dZ2nXxiab4bpk51p2lrVq1SqVU90PF8FLvCfBznTt/QgzZsxQ2WXt+l2Xa11xxRUq2/n03Xff7fn9Dz30UPzY7gudCVzxAgDgEI0XAACHaLwAADgUyhlvup9p6vXcyHTvd8tayNxi92UdMWJEQGeSXLI5mp3xpbIfbnNzs3ot8XmnIm6eeQotSvcjFBYWqjxx4kSVE/diEBGZNWuWyvb3tv3v1O79/Ne//vWCzvNCccULAIBDNF4AAByi8QIA4FAoZrz2Gaep7ilqn2maCr/73do1YKyFzC5ffvmlyvYegTFjxqh8ySWXqGxrN0ip7od70003qTxu3Lj4sX3eqZ3xwo0vvvgifmzXbdt9xnft2qXy2LFjM3diSezbt0/l4uJiX99v909IvK9H5NznXLvGFS8AAA7ReAEAcIjGCwCAQ7267AKn7v6gWQOWTuXl5Sone8ZpVVWVyi7Xnw0cOFDl0tJSle36sFTWQlp+10b28K8262WydisrK1Xetm2bynaOavf+PnbsWEbOS+TctZBHjhzx9f1+978tKCjo9r3sfDHZfJnajUln7fburW/pqa+vV9nenzBy5EiVT506pXIqtXvppZeqbPe8f/LJJ1W2PeDZZ59V2c5w0/08Xz96Urtc8QIA4BCNFwAAh2i8AAA4FMoZ7549e1R+8803Vb7jjjsydi6u2bWQb7/9drd/1q4Zvuqqq1S2cw3mZDGZrF3rgQceUNmuF7zzzjtVfuONNy74ZyWbk82bN0/lOXPmqOx3v1vLa/9be+8DM94LE+X7E/Lz81VOrL+amhr1mu0B9u//oosu8vxZYcKMFwCAkKHxAgDgEI0XAACHQrFXsxWlZ5wm43ctZN++fbt9L+Ze4ffqq6+qbJ/f7FcqczL77Gev+wfOJ5X9bu+9916V7R7mCJ79+12wYIHK9u932rRpKttnl9t97ZcsWaLy+PHjuz2XTz75RGW7TjfbcMULAIBDNF4AABwKxXKiVLcyc/moNbsN38SJE1X2u0TDa0nGsmXLPM/FPj7x9OnTnu+dq1wuJ7KPAbTstp533XWXyun8uM7WZrZtu5cLXNauHWusWLFCZTsms/z8nd1///0qb9y4scffG3YsJwIAIGRovAAAOETjBQDAoVDMeK0gH7Xmdxu+4uJiX+//wQcfqOy1ROPkyZO+3ttiThbjsnatr7/+WuWysjLPP5/OOdnUqVNVbmho6PF7B43ajQmydu39Crt27VJ5+PDhKnd2dqrc0dHR7XvffPPNKn/66acq2/tVooQZLwAAIUPjBQDAIRovAAAOhXLGa6X7UWuJ69Xso9L8Pq4qzGsjmZPFuKxdu857zZo1Ks+cOVPlZHMxOwtLlE1zMYvajQny924yye5fsH+HiVuYlpSUZOy8gsaMFwCAkKHxAgDgEI0XAACHQvlYQCvZo9Zee+01lf08rspr71uR5I+ritLaSLg3YcIElZPNf+wa9B07dqT9nIALYe9fSObzzz9XeciQIek8nUjjihcAAIdovAAAOETjBQDAoUjMeO2M9umnn1bZPgP3b3/7m8peczX7WjY/JxKZd88996h82WWXef555mCIimS1/dJLL6ls9zB455134scvv/yyes3ugZ/qPvVhxxUvAAAO0XgBAHCIxgsAgEORmPFa7e3tKjc3N6tsnxNp57iJ++Emey4k4MWubbTPhrZ77fqZg4l4z8KyfQ6GcElW2/Z+Bfsc9Q0bNsSP7XPOV65cqbLLPe2DwBUvAAAO0XgBAHCIxgsAgEORnPHauVoq++GyFy7SafLkySrbWvQzBxPxnoVl+xwMwbK/Z5PVduJzzs9n1apV8WNb17mGK14AAByi8QIA4BCNFwAAhyI542U/XITF6tWrVW5sbFR5xowZKvuZg4kwC0NwfvjhB5WT1fbSpUtVvuaaa1S2z1FPNHXqVJWz/f4FrngBAHCIxgsAgEM0XgAAHIrkjDed++Hm+nMhkZpFixapbGvtxx9/VDmVORjgUmdnp8q21svKylT+xS9+ofKZM2dU9qrtRx55ROWGhgaVs23myxUvAAAO0XgBAHCIxgsAgEO9upJtbPz/f9DMUV2ye4bu27dP5eLiYpUXLlyo8osvvqhy4gzYrpOsqKhQOcqzhR7+1WY9l7U7aNAglV944QWVZ86c6fn93377rcrDhg1T+Q9/+EP8+LnnnruQU4wEajcmyN+7ftnaP3z4cEBnEqye1C5XvAAAOETjBQDAoUh81JyXp///YNOmTSrbrcsWL16s8p///GeVf/7zn8eP7UfJfNScfaL0cZ1ll2BEuR79oHZjoly7uYqPmgEACBkaLwAADtF4AQBwKBJbRvrduozHUyFbUH9A9uGKFwAAh2i8AAA4ROMFAMChSKzjTSaVbfrsFn3ZNONlLWRMmGsX50ftxlC70cM6XgAAQobGCwCAQzReAAAcyooZbypaW1tVZsabfbK1drMZtRtD7UYPM14AAEKGxgsAgEM0XgAAHOrxjBcAAKQuJ694v/rqK5k1a5aUlpZKv3795Morr5RnnnlGOjo6gj41wBO1i6iids/KuSve1tZWGT16tBQUFEhNTY0MGjRImpqapLa2VqqqqqSuri7oUwTOi9pFVFG7WiQeC5hOr7zyirS3t8vHH38s5eXlIiLy4IMPSmdnp2zcuFGOHDkihYWFAZ8lcC5qF1FF7Wo591Hz0aNHRURkyJAh6utDhw6VvLw86dOnTxCnBSRF7SKqqF0t5xpvZWWliIjMnTtXdu/eLa2trfL666/LmjVrZOHChdK/f/9gTxDoBrWLqKJ2ja4ctGzZsq78/PwuEYn/s2TJkqBPC0iK2kVUUbtn5dyMV0SkrKxMbrzxRrntttukqKhItm7dKitWrJCSkhKZP39+0KcHdIvaRVRRuwmC7vyubd68uSs/P7+rtbVVfX327Nld/fr16zp06FBAZwZ4o3YRVdSulnMz3tWrV8vVV18tpaWl6utVVVXS0dEhLS0tAZ0Z4I3aRVRRu1rONd62tjY5c+bMOV8/deqUiIicPn3a9SkBPULtIqqoXS3nGu/IkSOlpaVF9u/fr76+efNmycvLk9GjRwd0ZoA3ahdRRe1qObdz1YcffihTpkyRoqIimT9/vhQVFcm7774r9fX1Ul1dLevXrw/6FIHzonYRVdSulnONV0SkublZnnrqKWlpaZHvv/9ehg8fLvfdd5889thj0rt3Tt7ojYigdhFV1O5ZOdl4AQAISs7NeAEACBKNFwAAh2i8AAA4ROMFAMAhGi8AAA7ReAEAcIjGCwCAQz1etdyrV69MngcygCXaMdRu9FC7MdRu9PSkdrniBQDAIRovAAAO0XgBAHCIxgsAgEM0XgAAHKLxAgDgEI0XAACHaLwAADhE4wUAwCEaLwAADtF4AQBwqMd7NQMI3tChQ+PHc+bMUa9Nnz7d83vHjx/v+fpHH32k8pYtW1TetGmTygcOHPB8PwDnxxUvAAAO0XgBAHCIxgsAgEM5OeO97rrr4sc7duxQryXO0ESSz9FSnZs999xznt8P9NS4ceM8X29qalK5b9++Kk+aNEnlG264QeXq6mqVH374YZW3b9/ek9MEch5XvAAAOETjBQDAoV5dXV1dPfqDvXpl+lzS5uKLL1b58ccfV3nx4sXx4/fee0+9NmHCBJWHDRvm+bPsR9X247uxY8eqbP9124+207lEo4d/tVkvSrWbOAYREXn00UdVTqzPZLX529/+VuXGxkaV8/L0/3cPGDBA5VGjRqls/1tpa2tT+dprr40fHzx40PPckqF2Y6JUu4jpSe1yxQsAgEM0XgAAHKLxAgDgUFYsJ+rfv7/KtbW1Kt96660qt7e3x49vueUW9dqhQ4dUXr9+vcp1dXUq+52b/e9//1P5X//6l8qJSzRYnpF9/Nx/ICLSp08flRPr09bqW2+95etcjh8/7pkHDx6ssj33/fv3q3zy5ElfPx/hkuz+gvnz56ucylLLXF9myRUvAAAO0XgBAHCIxgsAgENZsY63vLxc5c8++0zlEydOqFxVVRU/HjFihHpt3bp1aT47bfLkySp7rY1MXBcp4n9tJGshY4Ks3VTuPxAReeKJJ1TOdH0mGjhwoMqlpaUqf/PNNyofPXq0x+9tZ3zNzc0qP/LIIz1+r2yWztpN5/0FIiLFxcWeP89rjwO7v8F//vMflaO8HSnreAEACBkaLwAADtF4AQBwKJLreO1M17JzETtHff/998977IKftZGsi4y+srIyle1M195/MGPGDJVd16eXvXv3XvD33nTTTSrbRxgme6QhLkziPQZ+7y9YtGiRysnuL/jNb36jst3jIPGegWT7gG/YsEHlVO93CRuueAEAcIjGCwCAQzReAAAciuSM17Lrdnfv3q3yHXfc4fBsvDU0NKhcUVGhcuLaSD/rIkXOXRuJ8PFz/0HQ/NbfFVdcET+288G7775bZTvbLigo8Hl26InEewwyfX9BfX295+uJc9lc3wecK14AAByi8QIA4BCNFwAAhyI54/3yyy9VtuvFxowZo/Ill1yisl2v5pKdm/lZG2nXQlqshQw/u4+r3Ss8W9i9dpPtX2v3ff7Zz36W9nPKdWG6v8DPvS4i/u83CDuueAEAcIjGCwCAQzReAAAcyorn8VZWVqq8bds2le0cddKkSfHjY8eOZey8REQKCwtVPnLkiOef97MWMtnax7w8/r9KJNja7d1b30Zh1zra+xGskSNHquzy/gRbuxMnTlR5+vTpKs+aNSt+PGDAAPWafZ5qXV2dymvXrlXZrjHNVanWbmL92bWw//73v1W2z8iNEnv/yz//+U+V7bODDx8+nLFz4Xm8AACEDI0XAACHaLwAADgUyXW8lp0fLViwQGU7P0qnSy+9VOXq6mqV582bp/KcOXNU9jMns7MDu9Zt2bJlKq9fv76704Yjp0+fVnn58uWef97en2DXqKfz/gS/tWvnZF56eOtIXLbtxRsWifX3q1/9Sr32xhtvqBym/Q6sxHtfRESam5tVtve72PorKSlROZMz3p7gihcAAIdovAAAOETjBQDAoaxYx2vl5+ervGLFCpWbmprix3bOkey97Iy2pqZG5fLycpX9zroSffDBByonW/to52Sp/OxsEqXafeCBB1S2f8d33nln/Nh17dq1tc8++6zKtj4T+dmT/Hw/O1dlsnbPnDmj8sCBA1XO5D0Ezz//vHot2Rpxe/+B3/tdamtrVbb3XqQT63gBAAgZGi8AAA5lxXIi6/jx4yo//fTTKifeSm63VbTfu2TJEpXHjx/v+bM/+eQTle1HKH4+rvP78Ryi79VXX1V51KhRKr/22mvx40zXrq1N+yg3RIsdPdiPe3/88UeVk205m8oo48knn/Q+WcPvlqNhX57GFS8AAA7ReAEAcIjGCwCAQ1m5nCiZr7/+On5cVlamXvO7jOH+++9XeePGjSpPnTpVZZdzMpZkxES5du02frt27YofZ7p2g0TtxmSydr1qS0Tkj3/8o8rpvIcgcevT87H3NkTpfheWEwEAEDI0XgAAHKLxAgDgUFbOeAsLC1XeuXOnysOHD48fd3Z2qtc6Ojo83/vmm29W+dNPP1U5k1uR+cWcLCZKtZtM4jremTNnqteS1TK1Gz0uazextkSS11cyYb6HIJOY8QIAEDI0XgAAHKLxAgDgUFbu1XzPPfeofNlll6ns9Rm8fRRWSUlJ+k4MSNGECRPix8lmSbaWd+zYkZFzQjTZe2ESa0skeX3Zewjs+4XpnoGw4YoXAACHaLwAADhE4wUAwKGsnPHafUC91sJ9/vnnKg8ZMiQj5wRcCDs380Itw49k98JYtr7GjBmT9nPKFVzxAgDgEI0XAACHaLwAADiUFTNeOwebPHmyynY92rp16+LHdXV16rV33nlH5ZdfflnlefPmqXzy5El/Jwv44HcOl6ioqEhlahmJkt0L89JLL6lcXV2tsq2nuXPnpvHsshtXvAAAOETjBQDAIRovAAAOZcWM94cfflC5sbFR5RkzZqicuB5t27Zt6rUNGzaobOcaK1euVHnv3r3+ThbwwWsOZ2dwye5XsEaMGOH5OrWdXZLdC7NgwQKVX3zxRZXz8vR1Gr8bLxxXvAAAOETjBQDAIRovAAAOZcWMt7OzU+VFixapbGe8+fn53b7XqlWrVLZzDCCT/KxJt3vn+r1fYfbs2SpXVFT4OldEi70Xpri4WGWv34si/G5MJ654AQBwiMYLAIBDNF4AABzKihmvdeDAAZWbm5tVXrp0afz4mmuuUa+NGjXK872nTp2qMmvVkE5+1qQzk4Mf9l4Yr9+LIvxuzCSueAEAcIjGCwCAQzReAAAcysoZr/Xf//5X5QkTJsSPb7/9ds/v/fbbb1VuaGhI34kBRrI16WVlZfFjvzM5O3OzrzOjyy3Tpk1T+YUXXlB55syZnt/P78YLxxUvAAAO0XgBAHCoV1fiHnRefzDhcWSIhh7+1Wa9bKrdQYMGxY/9fjRo2Y8Kw/RRM7Ubk021myt6Urtc8QIA4BCNFwAAh2i8AAA4xIw3izEni6F2o4fajaF2o4cZLwAAIUPjBQDAIRovAAAO0XgBAHCIxgsAgEM0XgAAHKLxAgDgEI0XAACHaLwAADhE4wUAwCEaLwAADvV4r2YAAJC6nLzi/eqrr2TWrFlSWloq/fr1kyuvvFKeeeYZ6ejoCPrUAE/ULqKK2j0r5654W1tbZfTo0VJQUCA1NTUyaNAgaWpqktraWqmqqpK6urqgTxE4L2oXUUXtar2DPgHXXnnlFWlvb5ePP/5YysvLRUTkwQcflM7OTtm4caMcOXJECgsLAz5L4FzULqKK2tVy7qPmo0ePiojIkCFD1NeHDh0qeXl50qdPnyBOC0iK2kVUUbtazjXeyspKERGZO3eu7N69W1pbW+X111+XNWvWyMKFC6V///7BniDQDWoXUUXtGl05aNmyZV35+fldIhL/Z8mSJUGfFpAUtYuoonbPyrkZr4hIWVmZ3HjjjXLbbbdJUVGRbN26VVasWCElJSUyf/78oE8P6Ba1i6iidhME3fld27x5c1d+fn5Xa2ur+vrs2bO7+vXr13Xo0KGAzgzwRu0iqqhdLedmvKtXr5arr75aSktL1derqqqko6NDWlpaAjozwBu1i6iidrWca7xtbW1y5syZc75+6tQpERE5ffq061MCeoTaRVRRu1rONd6RI0dKS0uL7N+/X3198+bNkpeXJ6NHjw7ozABv1C6iitrVcm7nqg8//FCmTJkiRUVFMn/+fCkqKpJ3331X6uvrpbq6WtavXx/0KQLnRe0iqqhdLecar4hIc3OzPPXUU9LS0iLff/+9DB8+XO677z557LHHpHfvnLzRGxFB7SKqqN2zcrLxAgAQlJyb8QIAECQaLwAADtF4AQBwiMYLAIBDNF4AAByi8QIA4FCPF0/16tUrk+eBDGClWAy1Gz3Ubgy1Gz09qV2ueAEAcIjGCwCAQzReAAAcovECAOAQjRcAAIdovAAAOETjBQDAoax4COLQoUNVnjNnjsrLly93eToAAHSLK14AAByi8QIA4BCNFwAAh3p19XBT1CD3DL3uuutUfvTRR1WeMGGCysOGDVN5586dKo8fP77bn/XRRx+pvGXLFpU3bdqk8oEDB7p9r6Cx320M+91GD7UbQ+1GD3s1AwAQMjReAAAcovECAOBQKGa8F198scqPP/64yosXL1a5T58+Kh86dEjl4uJiz5+3Y8eO+HHfvn3Va2PHjlXZ/uvZt2+fyg8//LDK27dv9/zZLjEni2FOFj3Ubgy1Gz3MeAEACBkaLwAADjn7qLl///7x49raWvXarbfe6vm97e3tKj/xxBMqr1u3TuW1a9eqXFdXp3JjY2P8OC9P/7/HgAEDVB41apTK7733nsptbW0qX3755RIWfFwXw8d10UPtxoSpdpcsWaLy9OnTVfZapimil2pGeZlmMnzUDABAyNB4AQBwiMYLAIBDzh4LWFZWFj+2M90TJ06oXFVVpfL777/v62fV1NT4O7kEx48fV3nw4MEq26VP+/fvV/knP/mJygcPHrzgcwGAoNjHrVrjxo1TuampSWW7VHPSpEnx4xtuuEG9Vl1drbJdpmmFadnmheCKFwAAh2i8AAA4ROMFAMAhZzPeRHZtml0b63emm0kNDQ0qV1RUqLxq1SqVT548mfFzQu5KnLt99913AZ4Joi7Vx61aU6ZMUdlrjwS7P4KVbL+Ea6+9VuWo3UvDFS8AAA7ReAEAcIjGCwCAQ4HMeO1eliNGjAjiNHrk6NGjKu/du1flGTNmeP75ZBL3LxURaW5ujh8vX75cvXb48GFf743oefPNN1X2mrPt3LlTveZnr1yR7N4vFzGJ+w6k+rjV9evXq2z3wLfsngiJ+YMPPlCv3XHHHSon2y/B7700Xr9nRfTvWhe/Z7niBQDAIRovAAAO0XgBAHDI2fN4e/c+O06ur69Xr40ZM0blkSNHqmyfxxtlN910k8pvv/22yomzjauuukq9ZufLyfBM05ggn2n697//XeUvvvhCZb9ztrfeeit+bGdsS5cuVdnulTt27FiVbX3s27dP5fLycgkKtRvjt3YTn3suop99bvfI9/uc80waOHCgyqWlpSp/8803Kqd6L83111+vcuLvWr+/Zy2exwsAQMjQeAEAcIjGCwCAQ85mvIkqKytV3rZtm8r2M3Y7m8qkwsJClSdOnKjy1q1bPb//iiuuUHnRokUq33333SoXFBR0+152X2hmvBfG5YzXzkU/++wzzz+fzjmbnel67ZUrcu5+ucn2x7388st7fC6ponZjUp3xJs5C0/3c8zDzcy+NyLn30yTKxO9drngBAHCIxgsAgEM0XgAAHApkr+bt27ervGDBApXXrl2rsp1bHDt2LKWff+mll8aPq6ur1Wvz5s1Tec6cOSrbmdusWbNUtnM0y37+b9enLVu2LH5s9ydF9NgZnd2L2dZ6KnO2ZPvX2r1zBw8erLJd62j3IUf4lZWVqZxYf2F+7rlffu+lsfc/2N/De/bs6fbPZgJXvAAAOETjBQDAIRovAAAOBTLjtV599VWV7frCadOmqfzGG294vl9+fr7Kdk5bU1MTP7brLu1n/3b9VzJ2fm3307UzPa+5XOL+1oimZM+edjlns/vh2n2jU322NMItzM89T7Z/wvTp01VOdm9NsrW0XvfWuMAVLwAADtF4AQBwiMYLAIBDoRgi2vWF1muvvaay3YPWfv+SJUtUHj9+fLfv/cknn6j87LPPqvyPf/zD83U7w031WY6JTp8+nbb3ghtffvmlyo2NjSrbZ0+7ZGe26axVEb0OuLm5Wb22fPlylQ8fPpzWn43z85p1XnLJJSqH6bnnqd5bY6Vyr00mcMULAIBDNF4AABwK5LGAyXz99deer9tt0fw+Quz++++PH2/cuFG9NnXqVJUbGhp8vXeY8Gi1GJe1ayV7BGZRUZHKqW6Hmk7JtuWzH98lfjyY7LFryT7mpnZj/NauXYJYX18fP0425rBLbCZNmqSyy6167fKgZCM+K91jFD94LCAAACFD4wUAwCEaLwAADoVyxmuXD82cOVPlzs5Oz+/v6OhQ+eabb1b5008/jR9n85Id5mQxQc54H3jgAZXtMoY777xT5WTboXpJnKGJnDtHe/7551VOdVs+u/ykoKAgflxRUaFe8ztzo3ZjUq1de49BInu/gf07+tOf/qSyy616T5w4obJ9NGyYMeMFACBkaLwAADhE4wUAwKFQzHjtI6F27typcrJ1uwcPHlS5pKQkfScXYczJYoKc8dq514oVK1S2a2Ptdqhe7+c1QxM5d45m/zspLi72/FnWI488orKdV997773x49raWvWa33spqN2YTNZusvsP7M++6667VM7kVr1WlPZTYMYLAEDI0HgBAHCIxgsAgEOhmPEuWLBA5b/85S+eP3vPnj0qDxkyRGVmvDHMyWKCnPFa9lFsu3btUtnez/C73/1O5cQ5mtcMTeTcOZpdt7t06VKVM/mIS7+o3ZhM1q7f+w+sdO6Rn02Y8QIAEDI0XgAAHKLxAgDgUChmvHYP0Ntvv13ll156SWU7i3rnnXdUtvMD+6zHkydPXtB5Rg1zspgwzXitVPclT3TRRRel5ZzCgNqNcVm7fu8/sH9HfvbIt7Jpz3xmvAAAhAyNFwAAh2i8AAA41DuIH2r3Zp48ebLK9jPyzz//XGX7HMkNGzaobJ9DunLlSpWDXJ+I3GZrf8KECSr7mZt5zcwAv+zzlZubm1UePny4yrZWjx07pvKWLVtUZn+Fs7jiBQDAIRovAAAO0XgBAHAokBnvDz/8oHJjY6PKM2bMUNnuKWqtWrVKZTvjBcLi0KFDKvvdh3zHjh2ZOTHkPL/3H1htbW0q29rFWVzxAgDgEI0XAACHaLwAADgUyIzX7j9rn/to9wS1zw295pprVB41alT6Tg5II7sPuZ3p+t2HHMiUe+65R+XLLrvM888n20e6qKhI5Zdffjl+nKv75/8/rngBAHCIxgsAgEM0XgAAHArF83gHDRrk+foLL7ygsn1mqfXtt9+qbNf5Pvfccz7OLrp4pmmMy2ea5uXp/5f97rvvVC4uLlZ54cKFKr/44osq2xlw795nb8vI5jkZtRvjsnaTPRfd8nt/QuJ/GxUVFeq1bNo/n+fxAgAQMjReAAAcovECAOBQIOt4rcOHD3u+ftddd3lmq7W1VeWGhoYLOzHAJ7tGPd37kCfOwnjONFJh92Z+6KGHVLbPSbf3J6T6nPRcxhUvAAAO0XgBAHAoFB81p9tPf/rToE8BEJHMbofKR8tIxZEjR1S2S+F4XGvmcMULAIBDNF4AAByi8QIA4FBWzniBsDhw4IDK06ZNUznZdqh2+1O71R6QLi4f1zp16lSVc+1+Ba54AQBwiMYLAIBDNF4AABwKxWMBkRk8Wi2G2o0eajcmTLVrH9+ayuNas3nGy2MBAQAIGRovAAAO0XgBAHCIGW8WY04WQ+1GD7UbQ+1GDzNeAABChsYLAIBDNF4AABzq8YwXAACkjiteAAAcovECAOAQjRcAAIdovAAAOETjBQDAIRovAAAO0XgBAHCIxgsAgEM0XgAAHPo/MNW3i0rqIpwAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Converts images to tensors and normalize them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#train\n",
    "X_train_tensor = torch.tensor(X_train)/255.0\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "train_tensor = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "#val\n",
    "X_dev_tensor = torch.tensor(X_dev)/255.0\n",
    "y_dev_tensor = torch.tensor(y_dev)\n",
    "dev_tensor = TensorDataset(X_dev_tensor, y_dev_tensor)\n",
    "\n",
    "#test\n",
    "test_image_tensor = torch.tensor(test_npa)/255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defines data loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=64, num_workers=3, shuffle=True)\n",
    "dev_loader = DataLoader(dev_tensor, batch_size=64, num_workers=3, shuffle=True)\n",
    "test_loader = DataLoader(test_image_tensor, batch_size=64, num_workers=3, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define mode, loss and optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fits the model to data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = MyConNet5()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.50)\n",
    "trainer = MyTrainer(model, optimizer, loss_function)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1 epochs was 0.0274\n",
      "The loss after 2 epochs was 0.0232\n",
      "The loss after 3 epochs was 0.0252\n",
      "The loss had increased since the last checkpoint, stopping training!\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_loader, dev_loader, epochs=50, eval_every=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def make_predictions(data_loader):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    test_preds = torch.LongTensor()\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        #data = data.unsqueeze(1)\n",
    "\n",
    "        #if torch.cuda.is_available():\n",
    "        #    data = data.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        preds = torch.max(output, dim=1)[1] #output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_preds = torch.cat((test_preds, preds), dim=0)\n",
    "\n",
    "    return test_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "test_set_preds = make_predictions(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"./input/sample_submission.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      0\n4        5      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['Label'] = test_set_preds.numpy().squeeze()\n",
    "submission_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/myNet5t0.0258.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
