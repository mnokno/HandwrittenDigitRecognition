{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from trainer import MyTrainer\n",
    "from models import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checks for CUDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda enabled: True\n",
      "Compute device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \" + str(torch.cuda.is_available()))\n",
    "print(\"Cuda enabled: \" + str(torch.backends.cudnn.enabled))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"Compute device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Path management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base: str\n",
    "if os.getcwd() == \"/kaggle/working\":\n",
    "    base = \"/kaggle\"\n",
    "else:\n",
    "    base = os.getcwd()\n",
    "\n",
    "def get_full_dir(sub_dir: str) -> str:\n",
    "    return os.path.join(base, sub_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loads the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_path = get_full_dir(\"input/digit-recognizer/train.csv\")\n",
    "test_path = get_full_dir(\"input/digit-recognizer/test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Formats data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Separates labels\n",
    "x = df_train.drop(labels=\"label\", axis=1)\n",
    "y = df_train[\"label\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \nmean       0.0      0.0      0.0  ...      0.219286      0.117095   \nstd        0.0      0.0      0.0  ...      6.312890      4.633819   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reshapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "test_npa = df_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Updates shape to match image size 28x28x1 (only one channel per image)\n",
    "x = x.reshape(-1, 1, 28, 28)\n",
    "test_npa = test_npa.reshape(-1, 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Divides the train set to train and validation\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(x, y, test_size=0.2, random_state=8888)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Defines augmentation transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performs data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Performs data augmentation\n",
    "augmented_x_train = []\n",
    "augmented_y_train = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_train), y_train):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_train.append(transform(x_a))\n",
    "        augmented_y_train.append(y_a)\n",
    "    augmented_x_train.append(x_a)\n",
    "    augmented_y_train.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_train]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_train = np.concatenate(augmented_data_np, axis=0)\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_train = np.array(augmented_y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "augmented_x_dev = []\n",
    "augmented_y_dev = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_dev), y_dev):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_dev.append(transform(x_a))\n",
    "        augmented_y_dev.append(y_a)\n",
    "    augmented_x_dev.append(x_a)\n",
    "    augmented_y_dev.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_dev]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_dev = np.concatenate(augmented_data_np, axis=0)\n",
    "X_dev = X_dev.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_dev = np.array(augmented_y_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1041600 Dev size: 260400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \" + str(len(X_train)) + \" Dev size: \" + str(len(X_dev)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 9 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Converts data to tensors and normalize them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#train\n",
    "X_train_tensor = torch.tensor(X_train)/255.0\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "train_tensor = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "#val\n",
    "X_dev_tensor = torch.tensor(X_dev)/255.0\n",
    "y_dev_tensor = torch.tensor(y_dev)\n",
    "dev_tensor = TensorDataset(X_dev_tensor, y_dev_tensor)\n",
    "\n",
    "#test\n",
    "test_image_tensor = torch.tensor(test_npa)/255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defines data loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=64, num_workers=2, shuffle=True)\n",
    "dev_loader = DataLoader(dev_tensor, batch_size=64, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_image_tensor, batch_size=64, num_workers=2, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ensemble_size = 11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------[MyConNet6_0 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.649567\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.174610\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.121068\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.094502\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.081287\n",
      "Train Epoch: 0 Average Loss: 0.224207\n",
      "\n",
      "The loss after 1 epochs was 0.0321 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.065724\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.062810\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.055900\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.054237\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.052012\n",
      "Train Epoch: 1 Average Loss: 0.058137\n",
      "\n",
      "The loss after 2 epochs was 0.0227 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.045204\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043366\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.043222\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041289\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.041737\n",
      "Train Epoch: 2 Average Loss: 0.042964\n",
      "\n",
      "The loss after 3 epochs was 0.0236\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_0 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_1 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.612494\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.172003\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.117018\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.094781\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.082789\n",
      "Train Epoch: 0 Average Loss: 0.215817\n",
      "\n",
      "The loss after 1 epochs was 0.0297 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.065245\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.060665\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.057360\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.053660\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.051602\n",
      "Train Epoch: 1 Average Loss: 0.057706\n",
      "\n",
      "The loss after 2 epochs was 0.0253 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.045671\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.044105\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.042586\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041859\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.040319\n",
      "Train Epoch: 2 Average Loss: 0.042908\n",
      "\n",
      "The loss after 3 epochs was 0.0229 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.038749\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.037550\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.036782\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.035404\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.036700\n",
      "Train Epoch: 3 Average Loss: 0.037037\n",
      "\n",
      "The loss after 4 epochs was 0.0235\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_1 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_2 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.637473\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.177944\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.122081\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.097794\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.084506\n",
      "Train Epoch: 0 Average Loss: 0.223960\n",
      "\n",
      "The loss after 1 epochs was 0.0288 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.066973\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.062065\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.058852\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.055961\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.053425\n",
      "Train Epoch: 1 Average Loss: 0.059455\n",
      "\n",
      "The loss after 2 epochs was 0.0249 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.046354\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.045951\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.043984\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041840\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.042670\n",
      "Train Epoch: 2 Average Loss: 0.044160\n",
      "\n",
      "The loss after 3 epochs was 0.0217 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.039574\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.038631\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.036971\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.036560\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.037506\n",
      "Train Epoch: 3 Average Loss: 0.037848\n",
      "\n",
      "The loss after 4 epochs was 0.0197 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.035048\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.035601\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.035224\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.034619\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.034689\n",
      "Train Epoch: 4 Average Loss: 0.035036\n",
      "\n",
      "The loss after 5 epochs was 0.0203\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_2 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_3 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.621630\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.167784\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.114712\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.090854\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.076238\n",
      "Train Epoch: 0 Average Loss: 0.214244\n",
      "\n",
      "The loss after 1 epochs was 0.0271 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.063292\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.057403\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.054649\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.052170\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.049545\n",
      "Train Epoch: 1 Average Loss: 0.055412\n",
      "\n",
      "The loss after 2 epochs was 0.0237 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.044039\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.041990\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.040002\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.039242\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.039721\n",
      "Train Epoch: 2 Average Loss: 0.040999\n",
      "\n",
      "The loss after 3 epochs was 0.0214 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.036107\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.035864\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.035338\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.034327\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.034110\n",
      "Train Epoch: 3 Average Loss: 0.035149\n",
      "\n",
      "The loss after 4 epochs was 0.0219\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_3 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_4 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.628431\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.175859\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.119595\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.095753\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.082489\n",
      "Train Epoch: 0 Average Loss: 0.220425\n",
      "\n",
      "The loss after 1 epochs was 0.0324 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.066019\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.061451\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.057649\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.055039\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.051528\n",
      "Train Epoch: 1 Average Loss: 0.058337\n",
      "\n",
      "The loss after 2 epochs was 0.0228 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.046736\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043582\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.043831\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041764\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.041076\n",
      "Train Epoch: 2 Average Loss: 0.043398\n",
      "\n",
      "The loss after 3 epochs was 0.0216 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.037983\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.037624\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.037913\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.036573\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.036150\n",
      "Train Epoch: 3 Average Loss: 0.037249\n",
      "\n",
      "The loss after 4 epochs was 0.0209 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.034624\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.034030\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.035273\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.033299\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.033782\n",
      "Train Epoch: 4 Average Loss: 0.034202\n",
      "\n",
      "The loss after 5 epochs was 0.0212\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_4 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_5 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.651397\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.172563\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.116485\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.094096\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.078958\n",
      "Train Epoch: 0 Average Loss: 0.222700\n",
      "\n",
      "The loss after 1 epochs was 0.0332 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.063606\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.060414\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.056327\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.051866\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.050020\n",
      "Train Epoch: 1 Average Loss: 0.056447\n",
      "\n",
      "The loss after 2 epochs was 0.024 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.045024\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.041827\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.041888\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.040705\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.039298\n",
      "Train Epoch: 2 Average Loss: 0.041748\n",
      "\n",
      "The loss after 3 epochs was 0.0221 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.036466\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.036033\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.035797\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.034959\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.034540\n",
      "Train Epoch: 3 Average Loss: 0.035559\n",
      "\n",
      "The loss after 4 epochs was 0.0209 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.033091\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.033119\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.032409\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.032885\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.032773\n",
      "Train Epoch: 4 Average Loss: 0.032856\n",
      "\n",
      "The loss after 5 epochs was 0.0204 \n",
      "\n",
      "--------------------------------[MyConNet6_5 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_6 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.640091\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.174200\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.120725\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.094607\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.080359\n",
      "Train Epoch: 0 Average Loss: 0.221996\n",
      "\n",
      "The loss after 1 epochs was 0.0295 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.065216\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.059663\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.056004\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.054724\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.051422\n",
      "Train Epoch: 1 Average Loss: 0.057406\n",
      "\n",
      "The loss after 2 epochs was 0.0242 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.046224\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043317\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.042184\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.040967\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.040364\n",
      "Train Epoch: 2 Average Loss: 0.042611\n",
      "\n",
      "The loss after 3 epochs was 0.0225 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.037007\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.036136\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.037021\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.036563\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.035891\n",
      "Train Epoch: 3 Average Loss: 0.036524\n",
      "\n",
      "The loss after 4 epochs was 0.021 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.033441\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.034720\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.033555\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.033932\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.033515\n",
      "Train Epoch: 4 Average Loss: 0.033833\n",
      "\n",
      "The loss after 5 epochs was 0.0203 \n",
      "\n",
      "--------------------------------[MyConNet6_6 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_7 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.628342\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.171223\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.117501\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.094632\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.078451\n",
      "Train Epoch: 0 Average Loss: 0.218030\n",
      "\n",
      "The loss after 1 epochs was 0.0304 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.065382\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.059622\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.057588\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.053894\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.050541\n",
      "Train Epoch: 1 Average Loss: 0.057405\n",
      "\n",
      "The loss after 2 epochs was 0.025 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.043921\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043465\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.042372\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041430\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.040197\n",
      "Train Epoch: 2 Average Loss: 0.042277\n",
      "\n",
      "The loss after 3 epochs was 0.022 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.037160\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.037152\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.036243\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.035595\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.035697\n",
      "Train Epoch: 3 Average Loss: 0.036369\n",
      "\n",
      "The loss after 4 epochs was 0.0214 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.034257\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.034399\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.034423\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.033518\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.033906\n",
      "Train Epoch: 4 Average Loss: 0.034100\n",
      "\n",
      "The loss after 5 epochs was 0.0216\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet6_7 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_8 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.625718\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.170500\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.118429\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.095695\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.080806\n",
      "Train Epoch: 0 Average Loss: 0.218230\n",
      "\n",
      "The loss after 1 epochs was 0.0302 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.065116\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.060441\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.056441\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.054444\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.051352\n",
      "Train Epoch: 1 Average Loss: 0.057559\n",
      "\n",
      "The loss after 2 epochs was 0.0244 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.044875\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043095\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.043348\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041022\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.039614\n",
      "Train Epoch: 2 Average Loss: 0.042391\n",
      "\n",
      "The loss after 3 epochs was 0.0237 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.037454\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.036878\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.036455\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.035552\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.036024\n",
      "Train Epoch: 3 Average Loss: 0.036472\n",
      "\n",
      "The loss after 4 epochs was 0.0221 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.034034\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.032700\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.033347\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.034121\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.033660\n",
      "Train Epoch: 4 Average Loss: 0.033572\n",
      "\n",
      "The loss after 5 epochs was 0.021 \n",
      "\n",
      "--------------------------------[MyConNet6_8 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_9 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.620003\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.167394\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.115946\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.091237\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.078660\n",
      "Train Epoch: 0 Average Loss: 0.214648\n",
      "\n",
      "The loss after 1 epochs was 0.0279 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.063655\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.058868\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.055291\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.052196\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.050793\n",
      "Train Epoch: 1 Average Loss: 0.056160\n",
      "\n",
      "The loss after 2 epochs was 0.0217 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.043785\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.041646\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.039804\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041038\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.038109\n",
      "Train Epoch: 2 Average Loss: 0.040876\n",
      "\n",
      "The loss after 3 epochs was 0.0214 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.036189\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.035338\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.034857\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.034837\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.034485\n",
      "Train Epoch: 3 Average Loss: 0.035141\n",
      "\n",
      "The loss after 4 epochs was 0.0213 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.033051\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.032832\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.032176\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.032028\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.032620\n",
      "Train Epoch: 4 Average Loss: 0.032541\n",
      "\n",
      "The loss after 5 epochs was 0.0204 \n",
      "\n",
      "--------------------------------[MyConNet6_9 train end]---------------------------------\n",
      "-------------------------------[MyConNet6_10 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.622127\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.169348\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.119050\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.095578\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.078687\n",
      "Train Epoch: 0 Average Loss: 0.216958\n",
      "\n",
      "The loss after 1 epochs was 0.0284 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.064734\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.059404\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.056905\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.053931\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.051254\n",
      "Train Epoch: 1 Average Loss: 0.057246\n",
      "\n",
      "The loss after 2 epochs was 0.0237 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.044593\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.043319\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.042472\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041406\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.039921\n",
      "Train Epoch: 2 Average Loss: 0.042342\n",
      "\n",
      "The loss after 3 epochs was 0.0207 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.037992\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.036582\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.035539\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.035503\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.034787\n",
      "Train Epoch: 3 Average Loss: 0.036081\n",
      "\n",
      "The loss after 4 epochs was 0.0206 \n",
      "\n",
      "Current learning rate: [0.000125]\n",
      "Train Epoch: 4 [208320/1041600 (20%)]\t\tLoss: 0.034054\n",
      "Train Epoch: 4 [416640/1041600 (40%)]\t\tLoss: 0.033024\n",
      "Train Epoch: 4 [624960/1041600 (60%)]\t\tLoss: 0.034494\n",
      "Train Epoch: 4 [833280/1041600 (80%)]\t\tLoss: 0.033022\n",
      "Train Epoch: 4 [1041600/1041600 (100%)]\t\tLoss: 0.032745\n",
      "Train Epoch: 4 Average Loss: 0.033468\n",
      "\n",
      "The loss after 5 epochs was 0.0203 \n",
      "\n",
      "--------------------------------[MyConNet6_10 train end]---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, ensemble_size):\n",
    "    print(\"-------------------------------[MyConNet6_{} train start]--------------------------------\".format(i))\n",
    "    model = MyConNet6()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.5)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "    trainer = MyTrainer(model, optimizer, loss_function, lr_scheduler)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        loss_function = loss_function.cuda()\n",
    "\n",
    "    trainer.fit(train_loader, dev_loader, epochs=5, eval_every=1, sub_epoch_logs=True, sub_epoch_percentile=0.05)\n",
    "\n",
    "    torch.save(model.state_dict(), \"models/MyConNet6_\" + str(i) + \".pt\")\n",
    "    print(\"--------------------------------[MyConNet6_{} train end]---------------------------------\".format(i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model_predictions = []\n",
    "\n",
    "def make_predictions(eval_model, data_loader):\n",
    "    eval_model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        eval_model = eval_model.cuda()\n",
    "    test_predictions = torch.LongTensor().cuda()\n",
    "\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = eval_model(data)\n",
    "        predictions = torch.max(output, dim=1)[1]\n",
    "        test_predictions = torch.cat((test_predictions, predictions), dim=0)\n",
    "\n",
    "    return np.asarray(test_predictions.cpu())\n",
    "\n",
    "for i in range(0, ensemble_size):\n",
    "    model = MyConNet6()\n",
    "    model.load_state_dict(torch.load(\"models/MyConNet6_\" + str(i) + \".pt\"))\n",
    "    model_predictions.append(make_predictions(model, test_loader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2, 2, 2, ..., 2, 2, 2],\n       [0, 0, 0, ..., 0, 0, 0],\n       [9, 9, 9, ..., 9, 9, 9],\n       ...,\n       [3, 3, 3, ..., 3, 3, 3],\n       [9, 9, 9, ..., 9, 9, 9],\n       [2, 2, 2, ..., 2, 2, 2]], dtype=int64)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(model_predictions).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "       ImageId  Label\n0            1      2\n1            2      0\n2            3      9\n3            4      0\n4            5      3\n...        ...    ...\n27995    27996      9\n27996    27997      7\n27997    27998      3\n27998    27999      9\n27999    28000      2\n\n[28000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>27996</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>27997</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>27998</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>27999</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>28000</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finale_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=np.asarray(model_predictions))\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(finale_predictions.squeeze())+1)),\"Label\": finale_predictions})\n",
    "submissions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "pd.DataFrame(submissions).to_csv(\"submission.csv\", index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
