{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from trainer import MyTrainer\n",
    "from models import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checks for CUDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "Cuda enabled: True\n",
      "Compute device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \" + str(torch.cuda.is_available()))\n",
    "print(\"Cuda enabled: \" + str(torch.backends.cudnn.enabled))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"Compute device: \" + str(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Path management"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base: str\n",
    "if os.getcwd() == \"/kaggle/working\":\n",
    "    base = \"/kaggle\"\n",
    "else:\n",
    "    base = os.getcwd()\n",
    "\n",
    "def get_full_dir(sub_dir: str) -> str:\n",
    "    return os.path.join(base, sub_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data prep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loads the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_path = get_full_dir(\"input/digit-recognizer/train.csv\")\n",
    "test_path = get_full_dir(\"input/digit-recognizer/test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Formats data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Separates labels\n",
    "x = df_train.drop(labels=\"label\", axis=1)\n",
    "y = df_train[\"label\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\ncount  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \nmean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\ncount  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \nmean       0.0      0.0      0.0  ...      0.219286      0.117095   \nstd        0.0      0.0      0.0  ...      6.312890      4.633819   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n           pixel776     pixel777      pixel778      pixel779  pixel780  \\\ncount  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \nmean       0.059024      0.02019      0.017238      0.002857       0.0   \nstd        3.274488      1.75987      1.894498      0.414264       0.0   \nmin        0.000000      0.00000      0.000000      0.000000       0.0   \n25%        0.000000      0.00000      0.000000      0.000000       0.0   \n50%        0.000000      0.00000      0.000000      0.000000       0.0   \n75%        0.000000      0.00000      0.000000      0.000000       0.0   \nmax      253.000000    253.00000    254.000000     62.000000       0.0   \n\n       pixel781  pixel782  pixel783  \ncount   42000.0   42000.0   42000.0  \nmean        0.0       0.0       0.0  \nstd         0.0       0.0       0.0  \nmin         0.0       0.0       0.0  \n25%         0.0       0.0       0.0  \n50%         0.0       0.0       0.0  \n75%         0.0       0.0       0.0  \nmax         0.0       0.0       0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>...</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.00000</td>\n      <td>42000.000000</td>\n      <td>42000.000000</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n      <td>42000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.456643</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.219286</td>\n      <td>0.117095</td>\n      <td>0.059024</td>\n      <td>0.02019</td>\n      <td>0.017238</td>\n      <td>0.002857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.887730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.312890</td>\n      <td>4.633819</td>\n      <td>3.274488</td>\n      <td>1.75987</td>\n      <td>1.894498</td>\n      <td>0.414264</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.00000</td>\n      <td>254.000000</td>\n      <td>62.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reshapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "test_npa = df_test.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Updates shape to match image size 28x28x1 (only one channel per image)\n",
    "x = x.reshape(-1, 1, 28, 28)\n",
    "test_npa = test_npa.reshape(-1, 1, 28, 28)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Divides the train set to train and validation\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(x, y, test_size=0.2, random_state=8888)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Defines augmentation transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performs data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Performs data augmentation\n",
    "augmented_x_train = []\n",
    "augmented_y_train = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_train), y_train):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_train.append(transform(x_a))\n",
    "        augmented_y_train.append(y_a)\n",
    "    augmented_x_train.append(x_a)\n",
    "    augmented_y_train.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_train]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_train = np.concatenate(augmented_data_np, axis=0)\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_train = np.array(augmented_y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "augmented_x_dev = []\n",
    "augmented_y_dev = []\n",
    "num_augmentations = 30\n",
    "\n",
    "for x_a, y_a in zip(torch.tensor(X_dev), y_dev):\n",
    "    for i in range(num_augmentations):\n",
    "        augmented_x_dev.append(transform(x_a))\n",
    "        augmented_y_dev.append(y_a)\n",
    "    augmented_x_dev.append(x_a)\n",
    "    augmented_y_dev.append(y_a)\n",
    "\n",
    "#x = np.array(augmented_x)\n",
    "# Convert each tensor to a numpy array\n",
    "augmented_data_np = [x_t.numpy() for x_t in augmented_x_dev]\n",
    "# Concatenate all numpy arrays along the first axis\n",
    "X_dev = np.concatenate(augmented_data_np, axis=0)\n",
    "X_dev = X_dev.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_dev = np.array(augmented_y_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1041600 Dev size: 260400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \" + str(len(X_train)) + \" Dev size: \" + str(len(X_dev)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 9 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train samples\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i].squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Converts data to tensors and normalize them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#train\n",
    "X_train_tensor = torch.tensor(X_train)/255.0\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "train_tensor = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "#val\n",
    "X_dev_tensor = torch.tensor(X_dev)/255.0\n",
    "y_dev_tensor = torch.tensor(y_dev)\n",
    "dev_tensor = TensorDataset(X_dev_tensor, y_dev_tensor)\n",
    "\n",
    "#test\n",
    "test_image_tensor = torch.tensor(test_npa)/255.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defines data loaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "dev_loader = DataLoader(dev_tensor, batch_size=16, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_image_tensor, batch_size=16, num_workers=2, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "ensemble_size = 11"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------[MyConNet5_0 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n",
      "Train Epoch: 0 [52080/1041600 (5%)]\t\tLoss: 0.766691\n",
      "Train Epoch: 0 [104160/1041600 (10%)]\t\tLoss: 0.306111\n",
      "Train Epoch: 0 [156240/1041600 (15%)]\t\tLoss: 0.232153\n",
      "Train Epoch: 0 [208320/1041600 (20%)]\t\tLoss: 0.196053\n",
      "Train Epoch: 0 [260400/1041600 (25%)]\t\tLoss: 0.172775\n",
      "Train Epoch: 0 [312480/1041600 (30%)]\t\tLoss: 0.152506\n",
      "Train Epoch: 0 [364560/1041600 (35%)]\t\tLoss: 0.140522\n",
      "Train Epoch: 0 [416640/1041600 (40%)]\t\tLoss: 0.130080\n",
      "Train Epoch: 0 [468720/1041600 (45%)]\t\tLoss: 0.123769\n",
      "Train Epoch: 0 [520800/1041600 (50%)]\t\tLoss: 0.112428\n",
      "Train Epoch: 0 [572880/1041600 (55%)]\t\tLoss: 0.108750\n",
      "Train Epoch: 0 [624960/1041600 (60%)]\t\tLoss: 0.105258\n",
      "Train Epoch: 0 [677040/1041600 (65%)]\t\tLoss: 0.098902\n",
      "Train Epoch: 0 [729120/1041600 (70%)]\t\tLoss: 0.092739\n",
      "Train Epoch: 0 [781200/1041600 (75%)]\t\tLoss: 0.088365\n",
      "Train Epoch: 0 [833280/1041600 (80%)]\t\tLoss: 0.087929\n",
      "Train Epoch: 0 [885360/1041600 (85%)]\t\tLoss: 0.084505\n",
      "Train Epoch: 0 [937440/1041600 (90%)]\t\tLoss: 0.080821\n",
      "Train Epoch: 0 [989520/1041600 (95%)]\t\tLoss: 0.083659\n",
      "Train Epoch: 0 [1041600/1041600 (100%)]\t\tLoss: 0.075944\n",
      "Train Epoch: 0 Average Loss: 0.161998\n",
      "\n",
      "The loss after 1 epochs was 0.0249 \n",
      "\n",
      "Current learning rate: [0.001]\n",
      "Train Epoch: 1 [52080/1041600 (5%)]\t\tLoss: 0.065671\n",
      "Train Epoch: 1 [104160/1041600 (10%)]\t\tLoss: 0.064080\n",
      "Train Epoch: 1 [156240/1041600 (15%)]\t\tLoss: 0.066762\n",
      "Train Epoch: 1 [208320/1041600 (20%)]\t\tLoss: 0.062374\n",
      "Train Epoch: 1 [260400/1041600 (25%)]\t\tLoss: 0.063329\n",
      "Train Epoch: 1 [312480/1041600 (30%)]\t\tLoss: 0.060035\n",
      "Train Epoch: 1 [364560/1041600 (35%)]\t\tLoss: 0.058734\n",
      "Train Epoch: 1 [416640/1041600 (40%)]\t\tLoss: 0.058153\n",
      "Train Epoch: 1 [468720/1041600 (45%)]\t\tLoss: 0.060371\n",
      "Train Epoch: 1 [520800/1041600 (50%)]\t\tLoss: 0.057151\n",
      "Train Epoch: 1 [572880/1041600 (55%)]\t\tLoss: 0.057394\n",
      "Train Epoch: 1 [624960/1041600 (60%)]\t\tLoss: 0.057311\n",
      "Train Epoch: 1 [677040/1041600 (65%)]\t\tLoss: 0.059349\n",
      "Train Epoch: 1 [729120/1041600 (70%)]\t\tLoss: 0.054672\n",
      "Train Epoch: 1 [781200/1041600 (75%)]\t\tLoss: 0.055061\n",
      "Train Epoch: 1 [833280/1041600 (80%)]\t\tLoss: 0.052755\n",
      "Train Epoch: 1 [885360/1041600 (85%)]\t\tLoss: 0.056190\n",
      "Train Epoch: 1 [937440/1041600 (90%)]\t\tLoss: 0.052716\n",
      "Train Epoch: 1 [989520/1041600 (95%)]\t\tLoss: 0.051983\n",
      "Train Epoch: 1 [1041600/1041600 (100%)]\t\tLoss: 0.052391\n",
      "Train Epoch: 1 Average Loss: 0.058324\n",
      "\n",
      "The loss after 2 epochs was 0.0199 \n",
      "\n",
      "Current learning rate: [0.0005]\n",
      "Train Epoch: 2 [52080/1041600 (5%)]\t\tLoss: 0.047424\n",
      "Train Epoch: 2 [104160/1041600 (10%)]\t\tLoss: 0.044841\n",
      "Train Epoch: 2 [156240/1041600 (15%)]\t\tLoss: 0.045857\n",
      "Train Epoch: 2 [208320/1041600 (20%)]\t\tLoss: 0.048311\n",
      "Train Epoch: 2 [260400/1041600 (25%)]\t\tLoss: 0.044169\n",
      "Train Epoch: 2 [312480/1041600 (30%)]\t\tLoss: 0.048302\n",
      "Train Epoch: 2 [364560/1041600 (35%)]\t\tLoss: 0.045023\n",
      "Train Epoch: 2 [416640/1041600 (40%)]\t\tLoss: 0.042791\n",
      "Train Epoch: 2 [468720/1041600 (45%)]\t\tLoss: 0.046262\n",
      "Train Epoch: 2 [520800/1041600 (50%)]\t\tLoss: 0.043807\n",
      "Train Epoch: 2 [572880/1041600 (55%)]\t\tLoss: 0.045067\n",
      "Train Epoch: 2 [624960/1041600 (60%)]\t\tLoss: 0.042578\n",
      "Train Epoch: 2 [677040/1041600 (65%)]\t\tLoss: 0.042851\n",
      "Train Epoch: 2 [729120/1041600 (70%)]\t\tLoss: 0.041836\n",
      "Train Epoch: 2 [781200/1041600 (75%)]\t\tLoss: 0.041363\n",
      "Train Epoch: 2 [833280/1041600 (80%)]\t\tLoss: 0.041348\n",
      "Train Epoch: 2 [885360/1041600 (85%)]\t\tLoss: 0.039607\n",
      "Train Epoch: 2 [937440/1041600 (90%)]\t\tLoss: 0.041167\n",
      "Train Epoch: 2 [989520/1041600 (95%)]\t\tLoss: 0.042558\n",
      "Train Epoch: 2 [1041600/1041600 (100%)]\t\tLoss: 0.041636\n",
      "Train Epoch: 2 Average Loss: 0.043840\n",
      "\n",
      "The loss after 3 epochs was 0.0184 \n",
      "\n",
      "Current learning rate: [0.00025]\n",
      "Train Epoch: 3 [52080/1041600 (5%)]\t\tLoss: 0.039611\n",
      "Train Epoch: 3 [104160/1041600 (10%)]\t\tLoss: 0.037346\n",
      "Train Epoch: 3 [156240/1041600 (15%)]\t\tLoss: 0.037484\n",
      "Train Epoch: 3 [208320/1041600 (20%)]\t\tLoss: 0.039041\n",
      "Train Epoch: 3 [260400/1041600 (25%)]\t\tLoss: 0.040148\n",
      "Train Epoch: 3 [312480/1041600 (30%)]\t\tLoss: 0.037208\n",
      "Train Epoch: 3 [364560/1041600 (35%)]\t\tLoss: 0.039518\n",
      "Train Epoch: 3 [416640/1041600 (40%)]\t\tLoss: 0.038739\n",
      "Train Epoch: 3 [468720/1041600 (45%)]\t\tLoss: 0.035605\n",
      "Train Epoch: 3 [520800/1041600 (50%)]\t\tLoss: 0.038229\n",
      "Train Epoch: 3 [572880/1041600 (55%)]\t\tLoss: 0.037498\n",
      "Train Epoch: 3 [624960/1041600 (60%)]\t\tLoss: 0.038295\n",
      "Train Epoch: 3 [677040/1041600 (65%)]\t\tLoss: 0.035048\n",
      "Train Epoch: 3 [729120/1041600 (70%)]\t\tLoss: 0.036066\n",
      "Train Epoch: 3 [781200/1041600 (75%)]\t\tLoss: 0.039953\n",
      "Train Epoch: 3 [833280/1041600 (80%)]\t\tLoss: 0.035149\n",
      "Train Epoch: 3 [885360/1041600 (85%)]\t\tLoss: 0.037452\n",
      "Train Epoch: 3 [937440/1041600 (90%)]\t\tLoss: 0.037608\n",
      "Train Epoch: 3 [989520/1041600 (95%)]\t\tLoss: 0.036617\n",
      "Train Epoch: 3 [1041600/1041600 (100%)]\t\tLoss: 0.037074\n",
      "Train Epoch: 3 Average Loss: 0.037685\n",
      "\n",
      "The loss after 4 epochs was 0.0191\n",
      "The loss had increased since the last checkpoint, aborting training! \n",
      "\n",
      "--------------------------------[MyConNet5_0 train end]---------------------------------\n",
      "-------------------------------[MyConNet5_1 train start]--------------------------------\n",
      "Current learning rate: [0.002]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     11\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m     12\u001B[0m     loss_function \u001B[38;5;241m=\u001B[39m loss_function\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[1;32m---> 14\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_epoch_logs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_epoch_percentile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.05\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/MyConNet5_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--------------------------------[MyConNet5_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m train end]---------------------------------\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i))\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\HandwrittenDigitRecognition\\HandwrittenDigitRecognition\\src\\trainer.py:48\u001B[0m, in \u001B[0;36mMyTrainer.fit\u001B[1;34m(self, train_dataloader, test_dataloader, epochs, eval_every, early_stopping, sub_epoch_logs, sub_epoch_percentile)\u001B[0m\n\u001B[0;32m     45\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m---> 48\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m \u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m     labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mcuda()\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Zero your gradients for every batch!\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1, ensemble_size):\n",
    "    print(\"-------------------------------[MyConNet5_{} train start]--------------------------------\".format(i))\n",
    "    model = MyConNet5()\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.5)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)\n",
    "    trainer = MyTrainer(model, optimizer, loss_function, lr_scheduler)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        loss_function = loss_function.cuda()\n",
    "\n",
    "    trainer.fit(train_loader, dev_loader, epochs=5, eval_every=1, sub_epoch_logs=True, sub_epoch_percentile=0.05)\n",
    "\n",
    "    torch.save(model.state_dict(), \"models/MyConNet5_\" + str(i) + \".pt\")\n",
    "    print(\"--------------------------------[MyConNet5_{} train end]---------------------------------\".format(i))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_predictions = []\n",
    "\n",
    "def make_predictions(eval_model, data_loader):\n",
    "    eval_model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        eval_model = eval_model.cuda()\n",
    "    test_predictions = torch.LongTensor().cuda()\n",
    "\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = eval_model(data)\n",
    "        predictions = torch.max(output, dim=1)[1]\n",
    "        test_predictions = torch.cat((test_predictions, predictions), dim=0)\n",
    "\n",
    "    return np.asarray(test_predictions.cpu())\n",
    "\n",
    "for i in range(0, ensemble_size):\n",
    "    model = MyConNet5()\n",
    "    model.load_state_dict(torch.load(\"models/MyConNet5_\" + str(i) + \".pt\"))\n",
    "    model_predictions.append(make_predictions(model, test_loader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.asarray(model_predictions).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "finale_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=np.asarray(model_predictions))\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1,len(finale_predictions.squeeze())+1)),\"Label\": finale_predictions})\n",
    "submissions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(submissions).to_csv(\"submission.csv\", index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
